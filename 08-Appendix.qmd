# Appendix {-}

```{r appendix-setup, include=FALSE}
knitr::opts_chunk$set(
    echo = FALSE,
    message = FALSE,
    warning = FALSE
)
# Load package
library(dplyr)
library(tidyr)
library(purrr)
library(stringr)
library(forcats)
library(readr)
library(tibble)

library(codebook) # to generate codebook
library(here)
library(car) # for the type III SS in ANOVA
library(emmeans)
library(effectsize) # for equivalence tests and effect size estimation
library(GGally) # for ggpairs
library(apastats)
library(corrr)
source(here("r", "namifunc.R"))

# Dodge positions for plots
dodge_pos <- position_dodge(width = .5)

# ggplot theme
ggplot2::theme_set(ggplot2::theme_minimal())

# Default width for the violin plot
default_violin_width <- 0.4

# Load Datasets
s1e_df <- read_rds(here("data_public", "Study1e_public.rds"))
s2_df <- read_rds(here("data_public", "Study2_public.rds"))
s3_df <- read_rds(here("data_public", "Study3_public.rds"))

# Study 1a - Correlations Tables
s1a_target_vars <- read_rds(here("data_public", "subset", "Study1a_public_target.rds"))
s1b_target_vars <- read_rds(here("data_public", "subset", "Study1b_public_target.rds"))
s1c_target_vars <- read_rds(here("data_public", "subset", "Study1c_public_target.rds"))
s1d_target_vars <- read_rds(here("data_public", "subset", "Study1d_public_target.rds"))
s1e_target_vars <- read_rds(here("data_public", "subset", "Study1e_public_target.rds"))

# Cor CI Tables
s1b_cor_CIs  <- read_rds(here("data_public", "aggregate", "s1b_cor_CIs.rds"))
s1c_cor_CIs  <- read_rds(here("data_public", "aggregate", "s1c_cor_CIs.rds"))
s1d_cor_CIs  <- read_rds(here("data_public", "aggregate", "s1d_cor_CIs.rds"))
s1e_cor_CIs  <- read_rds(here("data_public", "aggregate", "s1e_cor_CIs.rds"))

# Long Datasets
s1c_df_long <- read_rds(here("data_public", "s1c_df_long.rds"))
s1d_dfC_long <- read_rds(here("data_public", "s1d_dfC_long.rds"))
s1e_df_long <- read_rds(here("data_public", "s1e_df_long.rds"))
```


## Detailed Description of the Measures included in Study 1

### Study 1a: Mass Testing

```{r appendix-s1a}
# Get Cronbach's alphas
s1a_realiablities <- read_rds(here("data_public", "reliability", "s1a_reliability.rds"))
s1a_cronbach_APA <- get_cronbach_alphas(s1a_realiablities) %>% 
  map(~f.round(., 2, strip.lead.zeros = T))
```

**Center for Epidemiologic Studies Depression Scale (CES-D).** The Center for Epidemiologic Studies Depression Scale is a 20-item measure of depressive symptoms [@radloffCESDScaleSelfReport1977]. Participants answered how frequently they experienced a depressive symptom (e.g., "I was bothered by things that usually don't bother me.") over a past week on a 4-point scale (0 = Rarely or none of the time, 1 = Some or little of the time [1--2 days], 2 = Occasionally or a moderate amount of time [3--4 days], 3 = Most or all of the time [5--7 days]). I used the sum of the scores as an index. Cronbach's alpha for the current sample was `r s1a_cronbach_APA$CESD_sum`.

**Patient-Reported Outcomes Measurement Information System (PROMIS) Social Isolation---Short Form 8a** The study used the Social Isolation subscale of the Patient-Reported Outcomes Measurement Information System (PROMIS), Short Form 8a [@cellaPROMISAdultHealth2019; @hahnNewEnglishSpanish2014]. The scale had 8 statements (e.g., "I felt left out"). For each statement, participants answered how they felt in the past four weeks on a 5-point scale (1 = Never, 2 = Rarely, 3 = Sometimes, 4 = Usually, 5 = Always). I calculated the average score as an index of social isolation. Cronbach's alpha for the current sample was `r s1a_cronbach_APA$social_isolation_mean`. The social isolation subscale demonstrated concurrent validity with other measures of social functioning [@hahnNewEnglishSpanish2014].

**Beliefs about Biological Differences between Blacks and Whites Scale**. The Beliefs about Biological Differences between Blacks and Whites Scale is a 15-item measure of the false beliefs about biological differences between Blacks and Whites [@hoffmanRacialBiasPain2016]. For each item (e.g., "Blacks have a more sensitive sense of smell than Whites; they can differentiate odors and detect faint smells better than Whites."), participants indicated how true each item is on a 6-point scale (1 = definitely untrue, 6 = definitely true). Among the 15 items, 4 items were fillers that described true differences ("Whites are less susceptible to heart disease like hypertension than Blacks", "Blacks are less likely to contract spinal cord diseases like multiple sclerosis", "Blacks, on average, have denser, stronger bones than Whites", "Whites are less likely to have a stroke than Blacks"). I calculated the average of the 11 items that describe false beliefs as an index. Cronbach's alpha for the current sample was `r s1a_cronbach_APA$bio_diff_mean`.

**Interpersonal Reactivity Scale.** The Interpersonal Reactivity Scale is a 28-item measure of a tendency to react to another person's experience [@davisMultidimensionalApproachIndividual1980]. The scale consisted of four subscales: perspective taking (one's tendency to adopt another's perspective), fantasy (tendency to transport themselves into the feelings and actions of characters in media), empathic concern (tendency to feel sympathy for others in misfortune), personal distress (tendency to feel anxiety in tense situations). For each item, participants read a statement (e.g., "I often have tender, concerned feelings for people less fortunate than me.") and indicated how much it describes themselves on a 5-point scale (0 = (A) does not describe me very well, 4 = (E) describes me very well). I calculated an average score within each subscale. Cronbach's alpha for the current sample were `r s1a_cronbach_APA$reactivity_mean` for the total score, `r s1a_cronbach_APA$reactivity_perspective` for perspective taking, `r s1a_cronbach_APA$reactivity_fantasy` for fantasy, `r s1a_cronbach_APA$reactivity_empathy` for empathic concern, and `r s1a_cronbach_APA$reactivity_distress` for personal distress. 

**Self-Monitoring Scale.** The self-monitoring scale is a 24-item measure of a tendency to self-observe and control one's behavior according to social appropriateness [@snyderSelfmonitoringExpressiveBehavior1974]. For each item, participants read a statement (e.g., "I find it hard to imitate the behavior of other people") and indicated whether the statement was true or mostly true (T) or false or usually not true (F). Each answer that corresponded with self-monitoring received a score of 1. I calculated the sum of the scores as an index.

**Paradox Mindset Scale.** The Paradox Mindset Scale is a 9-item measure of one's tendency to accept and get excited by tensions [@miron-spektorMicrofoundationsOrganizationalParadox2018]. Participants read statements (e.g., "When I consider conflicting perspectives, I gain a better understanding of an issue.") then indicated their agreement on a 7-point scale (-3 = strongly disagree to 3 = strongly agree). I calculated an average across items. Cronbach's alpha for the current sample was `r s1a_cronbach_APA$paradoxical_mindset_mean`.

**Integrative Complexity Scale.** The Integrative Complexity Scale is a 11-item measure of the capacity to acknowledge the competing opinions and to integrate different perspectives on an issue in an organizational setting [@zhangParadoxicalLeaderBehaviors2015]. For each item, participants read a statement (e.g., "I believe in the value of dissent.") and indicated their agreement on a 7-point scale. I calculated an average across items. Cronbach's alpha for the current sample was `r s1a_cronbach_APA$integrative_complexity_mean`.

**Multiple Identity Scale.** Four items from the Exeter Identity Transitions Scales [@haslamMaintainingGroupMemberships2008] measured membership to different social groups. Participants indicate their agreement on a statement (e.g., "I am a member of lots of different social groups.") on a 7-point scale (1 = do not agree at all, 7 = agree completely). I calculated an average as an index of multiple identity. Cronbach's alpha for the current sample was `r s1a_cronbach_APA$multiple_identity_mean`.

### Study 1b: RAIv1

```{r appendix-s1b}
# Get Cronbach's alphas
s1b_realiablities <- read_rds(here("data_public", "reliability", "s1b_reliability.rds"))
s1b_cronbach_APA <- s1b_realiablities %>% get_cronbach_alphas() %>%
  map(~f.round(., 2, strip.lead.zeros = TRUE))
```

Cronbach's alsphas for the current sample was `r s1b_cronbach_APA$PROMIS_isolation_sum` for the PROMIS Social Isolation Scale.

**MacArthur Scale of Subjective Social Status.** The MacArthur Scale of Subjective Social Status is a single-item measure of subjective social status [@adlerRelationshipSubjectiveObjective2000]. Participants saw a ladder with 10 rungs that represented where people stand in the United States. Participants answered where they place themselves in this ladder on a 11-point scale (0 = at the ground to 100 = the top rung, with 10-point increments).

**Patient-Reported Outcomes Measurement Information System (PROMIS) Emotional Support, and Informational Support---Short Form 8a.** The study used the Emotional Support and Informational Support subscales of the Patient-Reported Outcomes Measurement Information System (PROMIS), Short Form 8a [@cellaPROMISAdultHealth2019; @hahnNewEnglishSpanish2014]. Each subscales had 8 statements (e.g., "I had someone who listened to me when I needed to talk" for emotional support, and "I had someone to give me good advice about a crisis if I needed it" for informational support). For each statement, participants answered how they felt in the past four weeks on a 5-point scale (1 = Never, 2 = Rarely, 3 = Sometimes, 4 = Usually, 5 = Always). I calculated the sum scores for each subscale. Cronbach's alpha for the current sample were `r s1b_cronbach_APA$PROMIS_emotional_sum` for emotional support, and `r s1b_cronbach_APA$PROMIS_informational_sum` for informational support. The social support subscale demonstrated concurrent validity with other measures of social functioning [@hahnNewEnglishSpanish2014]. People without comorbidities reported lower informational support than those with comorbidities, demonstrating a construct validity by known groups [@hahnNewEnglishSpanish2014].

**Couple Satisfaction Index---4-item version**. The Couples Satisfaction Index---4-item Version is a measure of the quality of a romantic relationship [@funkTestingRulerItem2007]. The scale consisted of four items, (1) "Please indicate the degree of happiness, all things considered, of your relationship with your romantic partner during the past four weeks", (2) "I had a warm and comfortable relationship with my partner during the past four weeks", (3) "How rewarding was your relationship with your partner during the past four weeks?", (4) "In general, how satisfied were you with your relationship with your romantic partner during the past four weeks?". Participants used a 7-point scale to answer the first item (0 = Extremely Unhappy, 6 = Perfect) and a 6-point scale for the Items 2, 3, and 4 (1 = Not at all to 6 = Completely true for Item 2, Not at all to 6 = Completely for Items 3 and 4). I calculated the aggregated average as an index. Cronbach's alpha for the current sample was `r s1b_cronbach_APA$couples_satisfaction_mean`. The scale showed a convergent validity (r = .84--.94) with the other scales measuring relationship satisfaction [@funkTestingRulerItem2007].

**Inclusion of Other in Self Scale.** The Inclusion of Other in Self Scale is a single-item measure of closeness between the self and the other person [@aronInclusionOtherSelf1992]. The scale consisted of 7 pairs of circles (labeled "Self" and "Other") with varying degrees of overlap to each other (1 = no overlapping between Self and Other, 7 = highest overlap between Self and Other). Participants were instructed to select the picture that best describes their feeling to the person they wrote about in the essay. The scale showed convergent validity with verbal measures of closeness, especially for romantic relationships [@aronInclusionOtherSelf1992]. The test-retest reliability over a 2-week period ranged from _r_ = .83 to _r_ = .86 [@aronInclusionOtherSelf1992].

**Romantic Partner Responsiveness.** The study adopted three items measuring romantic partner responsiveness from a previous longitudinal study [@gableSafelyTestingAlarm2012]. The items were, "My [ex-] romantic partner understood me", "My [ex-] romantic partner made me feel like he/she valued my abilities and opinions.", and "My [ex-] romantic partner made me feel cared for". Participants indicated their answers on a 5-point scale (1 = Not at all, 5 = Very much). I calculated an average across 3 items as an index of partner responsiveness. Cronbach's alpha for the current sample was `r s1b_cronbach_APA$partner_resp_mean`.

**Relationship Conflict Scale.** Study 1c used a 3-item ad-hoc measure of relationship conflicts in the past four weeks. Items were: "How often did you and your [ex-romantic] partner have arguments or disagreements?", "How often did you and your [ex-] romantic partner have arguments or disagreements that were serious enough to negatively affect your relationship?", and "How often did you and your [ex-] romantic partner have unresolved conflicts or disagreements?". Participants indicated their answers on a 7-point scale (1 = Never, 7 = Regularly). I used an aggregated average as an index. Cronbach's alpha for the current sample was `r s1b_cronbach_APA$conflict_mean`.

**Ostracism from Romantic Partner Scale.** Study 1c used an ad-hoc 10-item measure of ostracism from a romantic partner developed for the study. Participants indicated their experience in the past 4 weeks (e.g., "[My partner/ex-romantic partner] Treated me as if I was invisible") on a 5-point scale (1 = Never, 5 = Always). I used an aggregated average as an index of ostracism from a romantic partner. Cronbach's alpha for the current sample was `r s1b_cronbach_APA$ostracism_mean`.

**Abusive Behavior Inventory---Psychological Abuse & Physical Abuse Subscales.** Study 1c useda modified version of the Psychological Abuse and Physical Abuse subscales of the Abusive Behavior Inventory---Revised [@postmusAbusiveBehaviorInventory2015], for measuring the perpetration of abusive behavior by participants against their romantic partner. The Psychological Abuse and Psychological Abuse subscales had 12 items and 11 items, respectively. Participants reported how often they perpetrated psychological (e.g., "Call your ex-romantic partner a name and/or criticize him/her") and physical (e.g., "Threaten to hit or throw something at your ex-romantic partner") abusive behaviors to their current and ex-romantic partner (if any) in the past four weeks on a 5-point scale (1 = Never, 5 = Very Often). I used an aggregated average for each subscale. Cronbach's alphas for the curent sample were `r s1b_cronbach_APA$abuse_psychological_mean` for the psychological abuse subscale. I was not able to calculate Cronbach's alpha for the physical abuse subscale given the high invariance in responses.

**Controlling Behavior Scale---Modified.** Study 1c used a modified version of the Controlling Behavior Scale [@donnellanAssociationLonelinessBathing2015] measuring perpetration of controlling behavior in a close relationship in five categories (economic control, threats, intimidation, emotional control, and isolation). Participants were asked to indicate how often they did the actions described in each item on a 5-point scale (0 = Never, 4 = Always). Example items were, "Make it difficult for your [ex-] romantic partner to work or study" for economic control, "Threaten to harm your [ex-] romantic partner" for threatening control, "Try to make your [ex-] partner do things they didn't want to" for intimidating control, "Try to put your [ex-] partner down when getting 'too big for his or her boots'" for emotional control, and "Try to restrict time your [ex-] partner spent with family or friends" for isolating control. I used an aggregated average for each subscale. Cronbach's alphas were `r s1b_cronbach_APA$control_economic_mean` the economic control, `r s1b_cronbach_APA$control_emotional_mean` for the emotional control, and `r s1b_cronbach_APA$control_isolation_mean` for the isolating control subscales. I was not able to calculate Cronbach's alpha given the invariance in the responses for threatening control and initimidation control. The scale showed a construct validity by differentiating criminally violent perpetrators and non-perpetrators [@graham-kevanPhysicalAggressionControl2003].

**Modified Food Cravings Questionnaire---Trait Version.** Study 1c used a modified version of the Food Cravings Questionnaire---Trait Version [@cepeda-benitoDevelopmentValidationState2000] is a trait measure of food cravings. Study 1c used the following 6 subscales: (1) Intentions and Plans to Consume Food (3 items; e.g., "Food cravings invariably made me think of ways to get what I wanted to eat"), (2) Lack of Control Over Eating (6 items; e.g., "When I craved something, I knew I wouldn't be able to stop eating once I started"), (3) Thoughts or Preoccupation with Food (7 items; e.g., "I felt like I had food on my mind all the time"), (4) Emotions (4 items; e.g., "I craved foods when I felt bored, angry, or sad"), (5) Cues that Trigger Food Cravings (4 items; e.g., "Being with someone who was eating often made me hungry"), and (6) Guilt From Cravings and/or for Giving Into Them (3 items; e.g., "I hated it when I gave in to cravings"). For each item, participants indicate their agreement on a 5-point scale (1 = Strongly disagree, 5 = Strongly agree). I calculated an aggregated average for each subscale and an overall index. Cronbach's alphas were `r s1b_cronbach_APA$craving_intent` for the intentions, `r s1b_cronbach_APA$craving_control` for lack of control, `r s1b_cronbach_APA$craving_thoughts` for thoughts, `r s1b_cronbach_APA$craving_emotions` for emotions, `r s1b_cronbach_APA$craving_cues` for cues, and `r s1b_cronbach_APA$craving_guilt` guilt subscales (overall alpha = `r s1b_cronbach_APA$craving_mean`). The scale showed convergent validity with the Eating Questionnaire [@stunkardThreefactorEatingQuestionnaire1985].

**Dietary Social Support Scale.** The ad-hoc dietary support scale was a 9-item scale measuring how much participants received support from their current romantic partner on their eating habits over the past 4 weeks. Participants saw statements about their partner (e.g., "Complimented me on my eating habits") and indicated their answer on a 5-point scale (1 = Never or almost never, 5 = Almost always). I calculated an average across items as an index. Cronbach's alpha for the current sample was `r s1b_cronbach_APA$dietary_support_mean`.

**Body Image Questionnaire.** The Body Image Questionnaire consisted of 9 images of female and male body images corresponding to BMIs of 17, 19, 22, 24, 26, 29, 33, 37, and 40 (the image available at: <https://web.archive.org/web/20200817174630/https://www.windbercare.org/do-you-know-the-difference-between-bmi-and-body-fat/>). Participants were asked to choose which of the images best represented themselves.

**Godin-Shephard Leisure-Time Physical Activity Questionnaire.** The Godin Leisure-Time Exercise Questionnaire is a 3-item measure of physical activity [@godinGodinShephardLeisureTimePhysical2011; @godinSimpleMethodAssess1985]. Participants answered how many times they did strenuous, moderate, and mild exercise per week on average in the past month. I used the following formula to calculate the weekly leisure-time activity scores: (9 x Strenuous) + (5 x Moderate) + (3 x Mild). People with the scores of 24 and more had lower body fat percentage and higher maximum rate of oxygen consumption (VO<sub>2</sub> max) than those with scores of 23 or less [@amireaultGodinShephardLeisuretimePhysical2015].

**PROMIS Sleep Disturbance---Short Form 4a.** The PROMIS Sleep Disturbance---Short Form 4a is a 4-item measure of sleep disturbance [@cellaPROMISAdultHealth2019]. Participants were asked about their sleep over the past four weeks. For the first item, participants indicate their general sleep quality on a 5-point scale("My sleep quality was:" 1 = Very poor, 5 = Very good, reverse-coded). For the items 2--4, participants rated their sleep quality ("My sleep was refreshing" (reverse-coded), "I had a problem with my sleep", and "I had difficulty falling asleep"). I calculated the sum of the scores with higher scores representing higher sleep disturbance. Cronbach's alpha for the current sample was XX. The scale had a concurrent validity with a measure of general health [@cellaPROMISAdultHealth2019].

**Single-Item Narcissism Scale.** The Single-Item Narcissism Scale is a 1-item measure of narcissism [@konrathDevelopmentValidationSingle2014]. Participants were asked, "To what extent do you agree with the statement: 'I am a narcissist.'". The scale provided the definition of a narcissist ("Note: The word "narcissist" means egotistical, self-focused, and vain."). Participants answered on a 7-point scale (1 = Not very true of me, 7 = Very true of me). The scale has a convergent validity with other measures of narcissism [@konrathDevelopmentValidationSingle2014].

**Perceived Stress Scale.** The Perceived Stress Scale is a 14-item measure of perceived stress [@cohenGlobalMeasurePerceived1983]. Participants indicated how frequently they experienced a stressful event in the past four weeks (e.g., How often have you been upset because of something that happened unexpectedly?) on a 5-point scale (0 = Never, 4 = Very often). I calculated an aggregated average as an index. Cronbach's alpha for the current sample was `r s1b_cronbach_APA$stress_mean`. The scale has a convergent validity with measures of depression, stressful life events, and physical symptoms, such as headache, back ache, and acid stomach [@cohenGlobalMeasurePerceived1983].

### Study 1c: ARv1
```{r appendix-s1c}
# Get Cronbach's alphas
s1c_realiablities <- read_rds(here("data_public", "reliability", "s1c_reliability.rds"))
s1c_cronbach_APA <- get_cronbach_alphas(s1c_realiablities) %>% map(~f.round(., 2, strip.lead.zeros = T))
```

**Modified Need-Threat Scale---Essay Version.** Study 1d used a modified version of the Need-Threat Scale [@williamsOstracismTemporalNeedthreat2009]. The scale consisted of the original 20 statements of the Need-Threat Scale. The instructions asked participants to think about their feelings when they recalled and wrote their essay. Participants indicated their agreement with each statement on a 5-point scale (1 = Strongly disagree, 5 = Strongly agree). I calculated an aggregated average for each subscale, and an overall average. Cronbach's alphas for the current sample was `r s1c_cronbach_APA$nts_mean`. for the overall score (belonging = `r s1c_cronbach_APA$nts_belonging_mean`, self-esteem = `r s1c_cronbach_APA$nts_esteem_mean`, control = `r s1c_cronbach_APA$nts_control_mean`, and meaningful existence = `r s1c_cronbach_APA$nts_meaning_mean`).

### Study 1d: EVv1
```{r appendix-s1d}
# Get Cronbach's alphas
s1d_realiablities <- read_rds(here("data_public", "reliability", "s1d_reliability.rds"))
s1d_cronbach_APA <- get_cronbach_alphas(s1d_realiablities) %>% map(~f.round(., 2, strip.lead.zeros = T))
```

**Need for Closure Scale.** The Need for Closure Scale was a 15-item measure of a need for closure, a desire for an answer on any topic [@roetsItemSelectionValidation2011]. Participants answered their agreement on statements (e.g., "I don't like situations that are uncertain") on a 7-point scale (-3 = strongly disagree, +3 = strongly agree). I will use the average score across items as an index for need for closure. The scale showed convergent validity with constructs, such as need for structure and right-wing authoritarianism, related to need for closure [@roetsItemSelectionValidation2011]. Cronbach's alpha for the current sample was `r s1d_cronbach_APA$closure_mean`.

**Social Judgment Survey.** The Social Judgement Survey is a single-item measure of adherence to the traditional cultural values [@proulxCaseTransmogrifyingExperimenter2008; @rosenblattEvidenceTerrorManagement1989]. The survey asks participants to read a case brief of a defendant accused of prostitution, and answer how much bond should be assigned to the defendant. Higher amounts of bond indicates higher adherence to the traditional cultural values, and lower bond indicates lower adherence. The scale was found sensitive to the mortality salience and expectancy violation manipulations [@proulxCaseTransmogrifyingExperimenter2008; @rosenblattEvidenceTerrorManagement1989].

### Study 1e: NPSv2
```{r appendix-s1e}
# Get Cronbach's alphas
s1e_realiablities <- read_rds(here("data_public", "reliability", "s1e_reliability.rds"))
s1e_cronbach_APA <- get_cronbach_alphas(s1e_realiablities) %>% map(~f.round(., 2, strip.lead.zeros = T))
```


**Modified Need-Threat Scale.** I used a modified version of the Need-Threat Scale [@nadzanModifiedNeedThreatScale2017] to measure feelings of belonging, self-esteem, and control [@williamsOstracismTemporalNeedthreat2009]. The original Need-Threat Scale asked participants to retrospectively report their feelings during a Cyberball game. Instead, this modified version asks participants to answer according to how they feel at the moment ("right now"). Example items included "How accepted do you feel?" for belonging, "How confident do you feel?" for self-esteem, "How much control do you feel like you have?" for control, and "How important do you feel?". Participants indicated their answers on a horizontal slider ranging from 0 (The least I could possibly ever feel) and 100 (the most I could ever possibly feel), to minimize floor and ceiling effects. I calculated an average for each subscale as an index. The Cronbach's alpha for the current sample was `r s1e_cronbach_APA$nts_T3_belonging_mean` (Time 3) and `r s1e_cronbach_APA$nts_T5_belonging_mean` (Time 5) for belonging, `r s1e_cronbach_APA$nts_T3_esteem_mean` (Time 3) and `r s1e_cronbach_APA$nts_T5_esteem_mean` (Time 5) for self-esteem, `r s1e_cronbach_APA$nts_T3_control_mean` (Time 3) and `r s1e_cronbach_APA$nts_T5_control_mean` (Time 5) for control, and `r s1e_cronbach_APA$nts_T3_meaning_mean` (Time 3) and `r s1e_cronbach_APA$nts_T5_meaning_mean` (Time 5) for meaningful existence. This modified scale has not been validated.

**Experiences in Close Relationships Scale---Short Form.** The Experiences in Close Relationships Scale---Short Form is a 12-item measure of attachment avoidance and anxiety [@weiExperiencesCloseRelationship2007]. Participants were asked to indicate their agreement on sentences referring to concerns in intimate relationships on a 7-point scale (-3 = "Strongly disagree" to 3 "Strongly agree"). Example items included "I want to get close to others but I keep pulling back" for avoidance and "I find that people don't want to get as close as I would like" for anxiety. I calculated an average for each subscale as an index. Cronbach's alphas for the current sample were `r s1e_cronbach_APA$ECR_avoidance_mean` for the avoidance subscale and `r s1e_cronbach_APA$ECR_anxiety_mean` for the anxiety subscale. Both subscales showed convergent and discriminant validities [@weiExperiencesCloseRelationship2007].

**Fear of Negative Evaluation Scale---Brief Version.** The Fear of Negative Evaluation is a 15-item measure of apprehension in expecting negative judgment from others [@learyBriefVersionFear1983]. For each item, participants read a sentence (e.g., "I worry about what other people will think of me even when I know it doesn't make any difference.") and rated how characteristic it is of themselves on a 5-point scale (1 = "Not at all characteristic of me" and 5 = "Extremely characteristic of me"). I calculated an average across 15 items as an index of fear of negative evaluation. Cronbach's alpha for the current sample was `r s1e_cronbach_APA$FNES_mean`. The scale showed convergent validity with existing measures of social avoidance and anxiety [@learyBriefVersionFear1983].

**Rosenberg Self-Esteem Scale.** The Rosenberg Self-Esteem Scale is a 10-item measure of self-esteem [@rosenbergMeasurementSelfEsteem1965]. Participants answered how much they agreed to statements (e.g., "I feel that I am a person of worth, at least on an equal basis with others.") on a 7-point scale (-3 = "Strongly disagree" to 3 = "Strongly agree"). I calculated an average across 10 items as an index of self-esteem. Cronabch's alpha for the current sample was `r s1e_cronbach_APA$esteem_mean`. The scale has convergent validity with measures of optimism, life satisfaction, and narcissism [@rosenbergMeasurementSelfEsteem1965].

**Rejection Sensitivity Questionnaire---Short Version.** The Rejection Sensitivity Questionnaire---Short Version is an 8-item version of the Rejection Sensitivity Questionnaire [@downeyImplicationsRejectionSensitivity1996; @romero-canyasPayingBelongWhen2010]. The scale consisted of 8 scenarios describing a situation that can possibly evoke social rejection by another person (e.g., "You ask your parents for help in deciding what programs to apply to."). All items are relevant to the college student sample. For each scenario, participants rated (a) how concerned or anxious they were about how the other person would respond (1= Not at all concerned, 6 = Very concerned), and (b) how much they expected rejection to happen (1 = Very unlikely, 6 = Very likely) on a 6-point scale (ranging from 1 = Not at all concerned or very unlikely to 6 = very concerned or very likely). Following the scoring guidelines, I created a scale composite by multiplying the two responses for each scenario (a and b) and averaging across the multiplied scores. Cronbach's alpha for the current sample was `r s1e_cronbach_APA$RS_mean`.


## Supplementary Figures and Analyses by Study

### Study 1

#### Study 1a


```{r}
knitr::write_bib(c(.packages(), "bookdown"), "packages.bib")
```


```{r appendix-s1a-correlations-table}
#| label: tbl-appendix-s1a-correlations-table
# Means, SD, and Bivariate Correlations Table
# Reference: https://www.datadreaming.org/post/apa-tables-using-rmarkdown-part-3/
# Footnote for the table
s1a_footnote <- "Heart = Heart Manikin, Valence = Valence Self-Assessment Manikin,"
# Table Title
s1a_title <- "Study 1a - Descriptive Statistics and Correlations among Variables"
# N, Mean, SD Table
s1a_mnsdcor <- s1a_target_vars %>% get_nmsd_cor_table()
# Render table
s1a_mnsdcor %>% as_tibble() %>%
  render_APA_kable(col1_width = "1.5in",
                   title = s1a_title) %>%
  footnote(general_title = "", general = "CESD = Center for Epidemiological Studies - Depression Scale") %>% 
  footnote(general_title = "Note.",
           general = s1a_footnote,
           footnote_as_chunk = TRUE) %>%
  kable_styling_cortable()
```


#### Study 1b

```{r appendix-s1b-correlations-table}
# N, Mean, SD Table
s1b_mnsdcor <- s1b_target_vars %>% dplyr::select(-id, -visit) %>% get_nmsd_cor_table()

# Footnote for the table
s1b_footnote <- paste(sep = " ",
                      "Heart = Heart Manikin, Valence = Valence Self-Assessment Manikin, SES = Subjective Socioeconomic Status,", "IOS = Inclusion of the Other in the Self Scale, CESD = Center for Epidemiological Studies - Depression Scale")

# Render table
s1b_mnsdcor %>% as_tibble() %>%
  render_APA_kable(col1_width = "1.5in",
                   title = "Study 1b - Descriptive Statistics and Correlations among Variables") %>%
  footnote(general_title = "Note.",
           general = s1b_footnote,
           footnote_as_chunk = TRUE, threeparttable = TRUE) %>% 
  kable_styling_cortable()


```

```{r appendix-s1b-forest, fig.cap='Study 1b (RAIv1) - Forest plot of correlation coefficients of the measured variables with the Heart Manikin Scores', fig.width=10, fig.height=12, chache=TRUE}
# Forest plot for all the correlations acros Times 1-3 (Appendix)
ggplot(s1b_cor_CIs,
       aes(y=label, x=estimate,
           color = type)) +
  #Add data points and color them black
  geom_point()+
  #add the CI error bars - 90%
  geom_errorbarh(aes(xmin = conf.low_model90, xmax = conf.high_model90), height = .5, size = .5) +
  #add the CI error bars - 95%
  geom_errorbarh(aes(xmin = conf.low_model95, xmax = conf.high_model95), height = .5, size = .5) +
  #Specify the limits of the x-axis and relabel it to something more meaningful
  scale_x_continuous(limits=c(-1,1), name='Correlation Coefficient with Heart Manikin')+
  #Give y-axis a meaningful label
  ylab('Variable') +
  # Legend
  scale_color_discrete(name = "Hypothesized\nValidity") +
  #Add a vertical dashed line indicating an effect size of zero, for reference
  geom_vline(xintercept=0, color='black', linetype='dashed') +
  #Create sub-plots (i.e., facets) based on levels of setting
  #And allow them to have their own unique axes (so authors don't redundantly repeat)
  ## Facet nested
  # facet_grid(type+time~outcome, scales= 'free', space='free') +
  ggh4x::facet_nested(type + time ~ outcome, scales= 'free', space='free') +
  ggtitle("Study 1b (RAIv1): Correlation Coefficients with the Heart Manikin\nacross Visits 1-3") +
  # Add SESOI lines
  SESOIgeom +
  # caption
  labs(caption = s1_caption_errorbars9095)
```

#### Study 1c (ARv1)

```{r appendix-s1c-correlations-table}
s1c_footnote <- "Heart = the Heart Manikin, SES = Subjective Socioeconomic Status, IOS = Inclusion of the Other in the Self Scale, NTS = the Need-Threat Scale"

# N, M, SD, Cor tables
s1c_mnsdcor <- s1c_target_vars %>% get_nmsd_cor_table()
# Render table
s1c_mnsdcor %>% as_tibble() %>%
  render_APA_kable(col1_width = "1.5in",
                   title = "Study 1c - Descriptive Statistics and Correlations among Variables") %>%
  footnote(general_title = "Note.",
           general = s1c_footnote,
           footnote_as_chunk = TRUE, threeparttable = TRUE) %>% 
  kable_styling_cortable()
```

```{r appendix-s1c-all-cors-plot, fig.cap='Study 1c - Forestplot of Correlation Coefficients between the Measured Variabels with the Heart Manikin', fig.width=9, fig.height=5}
# Forestplot - all correlations, except the ones for the mixed model
s1c_cor_CIs %>%
  ggplot(aes(y = label, x = estimate,
             color = type)) +
  # Dta points
  geom_point()+
  # CI error bars - 90%
  geom_errorbarh(aes(xmin = conf.low_model90, xmax = conf.high_model90), height = .3, size = .3) +
  # CI error bars - 95%
  geom_errorbarh(aes(xmin = conf.low_model95, xmax = conf.high_model95), height = .3, size = .3) +
  # Specify the limits of the x-axis and relabel it to something more meaningful
  scale_x_continuous(limits=c(-1,1), name='Correlation Coefficient with Heart Manikin')+
  #Give y-axis a meaningful label
  ylab('Variable') +
  # Legend labels
  scale_color_discrete(name = "Hypothesized\nValidity") +
  #Add a vertical dashed line indicating an effect size of zero, for reference
  geom_vline(xintercept=0, color='black', linetype='dashed') +
  # Facet nested
  ggh4x::facet_nested(type + time ~ outcome, scales= 'free', space='free') +
  ggtitle("Study 1c (ARv1): Correlation Coefficients with the Heart Manikin") +
  # Add SESOI
  SESOIgeom +
    # caption
  labs(caption = s1_caption_errorbars9095)
```

I explored whether the heart manikin scores changed across time by condition in a mixed model.

```{r appendix-s1c-mixed}
s1c_sensitivity_mixed_df <- tibble(outcome = c("heart", "valence")) %>%
  dplyr::mutate(formula = paste0(outcome, "~ grouping_dummy * time + (1|id)")) %>%
  dplyr::mutate(model = map(formula, ~lmer(formula = ., data = s1c_df_long))) %>%
  dplyr::mutate(tidy = map(model, ~broom.mixed::tidy(.)),
         APA = map(model, ~describe.glm(.)))
```

```{r appnedix-s1c-belonging-across-time, fig.cap='Study 1c - Heart Manikin Scores Across Time and Conditions', fig.width=8, fig.height=11}
#| label: fig-appnedix-s1c-belonging-across-time
s1c_heart_across_time_plot <- s1c_df_long %>%
  ggplot(aes(x = time, y = heart, color = grouping_dummy, group = grouping_dummy)) +
  # Plot Data Points
  geom_point(position = position_jitterdodge(jitter.height = 1,
                                             jitter.width = .05, dodge.width = my_dodge_width),
             size = .2) +
  # Add line to connect the groups
  geom_line(stat = "summary", fun.data = mean_cl_normal, position = dodge_pos) +
  geom_errorbar(fun.data = mean_cl_normal, stat = "summary", width = .3,
                position = dodge_pos, color = "black") +
  # Plot means
  geom_point(stat = "summary", fun.data = mean_cl_normal,
             shape = 21, aes(fill = grouping_dummy), color = "black",
             position = dodge_pos) +
  # Labels
  xlab("Time") +
  ylab("Heart Manikin") +
  scale_fill_brewer(palette = "Set2") +
  scale_color_brewer(palette = "Set2", name = "Condition") +
  guides(fill = FALSE) +
  labs(caption = "Participants completed the essay between Time 1 and Time 2. \nErrorbars represent 95% confidence intervals")

s1c_valence_across_time_plot <- s1c_df_long %>%
  ggplot(aes(x = time, y = valence, color = grouping_dummy, group = grouping_dummy)) +
  # Plot Data Points
  geom_point(position = position_jitterdodge(jitter.height = 1,
                                             jitter.width = .05, dodge.width = my_dodge_width),
             size = .2) +
  # Add line to connect the groups
  geom_line(stat = "summary", fun.data = mean_cl_normal, position = dodge_pos) +
  geom_errorbar(fun.data = mean_cl_normal, stat = "summary", width = .3,
                position = dodge_pos, color = "black") +
  # Plot means
  geom_point(stat = "summary", fun.data = mean_cl_normal,
             shape = 21, aes(fill = grouping_dummy), color = "black",
             position = dodge_pos) +
  # Labels
  xlab("Time") +
  ylab("Valence Manikin") +
  scale_fill_brewer(palette = "Set2") +
  scale_color_brewer(palette = "Set2", name = "Condition") +
  guides(fill = FALSE) +
  labs(caption = "Participants completed the essay between Time 1 and Time 2. \nErrorbars represent 95% confidence intervals")

ggarrange(s1c_heart_across_time_plot,
          s1c_valence_across_time_plot,
          nrow = 2, labels = "AUTO")
```

#### Study 1d (EVv1)

```{r appendix-s1d-correlations-table}
s1d_footnote <- "Heart = the Heart Manikin, NTS = the Need-Threat Scale"

# N, Mean, SD Table
s1d_mnsdcor <- s1d_target_vars %>% get_nmsd_cor_table()
# Render table
s1d_mnsdcor %>% as_tibble() %>%
  render_APA_kable(title = "Study 1d - Descriptive Statistics and Correlations among Variables",
                   footnote = s1d_footnote) %>%
  kable_styling_cortable()
```

```{r appendix-s1d-all-forestplot, fig.cap='Study 1d - Forestplot of Correlation Coefficients between the Measured Scores and the Heart Manikin',fig.width=10, fig.height=12}
## Forestplot
s1d_cor_CIs %>%
  ggplot(aes(y = forcats::fct_inorder(label), x = estimate, color = type)) +
  # SESOI and ZERO
  geom_zeroSESOI +
  # Dta points
  geom_point()+
  # CI error bars - 90%
  geom_errorbarh(aes(xmin = conf.low_model90, xmax = conf.high_model90), height = .3, size = .3) +
  # CI error bars - 95%
  geom_errorbarh(aes(xmin = conf.low_model95, xmax = conf.high_model95), height = .3, size = .3) +
  # x-axis label and limits
  scale_x_continuous(limits=c(-1,1), name='Correlation Coefficient with Heart Manikin')+
  # y-axis label
  ylab("Measure") +
  # Legend Title
  scale_color_discrete(name = "Hypothesized \nValidity") +
  # Facet the graph by type, time, and outcome
  ggh4x::facet_nested(type + time ~ outcome, scales= 'free', space='free') +
  # Title
  ggtitle("Study 1d (EVv1) - Correlation Coefficients with \nthe Heart Manikin") +
  # Caption
  labs(caption = paste(sep = "\n",
                       "Errorbars represent 90% (inner tick) and 95% (outer tick) confidence intervals",
                       sprintf("The vertical dashed line represents the smallest effect size of interest (SESOI, |r| = %s)", SESOI_r),
                       "Participant Desire Manipulation happened between Times 1 and 2.",
                       "Rejection Manipulation happened between Times 2 and 3."))
```

```{r appendix-s1d-sensitivity-plot, fig.cap='Study 1d - Heart Manikin Across Time', fig.width=8, fig.height=6}
# s1d Plot - Heart by Condition across time
s1d_heart_across_time_plot <- s1d_dfC_long %>%
  ggplot(aes(x = time, y = heart, color = paste(rejection, confederate_desire), group = paste(rejection, confederate_desire))) +
  # Plot Data Points
  geom_point(position = position_jitterdodge(jitter.height = 1,
                                             jitter.width = .05, dodge.width = my_dodge_width),
             size = .2) +
  # Add line to connect the groups
  geom_line(stat = "summary", fun.data = mean_cl_normal, position = dodge_pos) +
  geom_errorbar(fun.data = mean_cl_normal, stat = "summary", width = .3,
                position = dodge_pos, color = "black") +
  # Plot means
  geom_point(stat = "summary", fun.data = mean_cl_normal,
             shape = 21, aes(fill = paste(rejection, confederate_desire)), color = "black",
             position = dodge_pos) +
  # Labels
  xlab("Time") +
  ylab("Heart Manikin") +
  scale_fill_brewer(palette = "Set2") +
  scale_color_brewer(palette = "Set2", name = "Condition") +
  guides(fill = FALSE) +
  labs(caption = "Participants completed the essay between Time 2 and Time 3.\nErrorbars represent 95% confidence intervals")

s1d_heart_across_time_plot

```

#### Study 1e (NPSv2)

```{r appendix-s1e-correlations-table}
# Footnote
s1e_footnote <- "Heart = the Heart Manikin, NTS = the Need-Threat Scale"
# Get nmsdtable
s1e_mnsdcor <- get_nmsd_cor_table(s1e_target_vars)
# Render table
s1e_mnsdcor %>% as_tibble() %>%
  render_APA_kable(title = "Study 1e - Descriptive Statistics and Correlation Coefficients",
                   footnote = s1e_footnote) %>%
  kable_styling_cortable()
```

```{r appendix-s1e-cor-forestplot, fig.cap='Study 1e - Forestplot of Correlations between the Measured Variables and the Heart Manikin Scores', fig.width = 14, fig.height = 14}
# Study 1e - Correlations Forest Plot
s1e_cor_CIs %>%
  ggplot(aes(y = label, x = estimate, color = type)) +
  # SESOI and Zero
  geom_zeroSESOI +
  # Data points
  geom_point()+
  # CI error bars - 90%
  geom_errorbarh(aes(xmin = conf.low_model90, xmax = conf.high_model90), height = .3, size = .3) +
  # CI error bars - 95%
  geom_errorbarh(aes(xmin = conf.low_model95, xmax = conf.high_model95), height = .3, size = .3) +
  # x-axis limits and label
  scale_x_continuous(limits=c(-1,1), name='Correlation Coefficient')+
  # y-axis label
  ylab('Variable') +
  # Legend Title
  scale_color_discrete(name = "Hypothesized \nValidity") +
  # Facet nested
  ggh4x::facet_nested(type + time ~ outcome, scales= 'free', space='free') +
  # Title
  ggtitle("Study 1e (NPSv2): Correlation Coefficients with Heart Manikin Scores") +
  # Caption
  labs(caption = "") +
  # Add SESOI
  SESOIgeom +
  # caption
  labs(caption = s1_caption_errorbars9095)
```

I explored whether participants reported different levels of belonging across time, depending on the experimental conditions. @fig-appendix-s1e-belonging-plot shows the Heart Manikin scores across time and the conditions.

```{r appendix-s1e-belonging-plot, fig.cap='Study 1e - Heart Manikin Scores', fig.width=8, fig.height=5}
#| label: fig-appendix-s1e-belonging-plot
# s1e Plot - Heart by Condition across time
s1e_heart_plot <- s1e_df_long %>%
  dplyr::mutate(across(c(rejection, confederate_desire), to_factor)) %>%
  ggplot(aes(x = time, y = heart, color = paste(rejection, confederate_desire),
             group = paste(rejection, confederate_desire))) +
  # Plot Data Points
  geom_point(position = position_jitterdodge(jitter.height = 1,
                                             jitter.width = .05, dodge.width = my_dodge_width),
             size = .2) +
  # Add line to connect the groups
  geom_line(stat = "summary", fun.data = mean_cl_normal, position = dodge_pos) +
  geom_errorbar(fun.data = mean_cl_normal, stat = "summary", width = .3,
                position = dodge_pos, color = "black") +
  # Plot means
  geom_point(stat = "summary", fun.data = mean_cl_normal,
             shape = 21, aes(fill = paste(rejection, confederate_desire)), color = "black",
             position = dodge_pos) +
  # Labels
  ggtitle("Heart Manikin Scores across Time") +
  xlab("Time") +
  ylab("Heart Manikin") +
  scale_fill_brewer(palette = "Set2") +
  scale_color_brewer(palette = "Set2", name = "Condition") +
  guides(fill = FALSE) +
  labs(caption = paste(sep = "\n",
                       "Participants completed the confederate desire manipulation between Times 2 and 3",
                       "Participants completed the rejection essay between Times 4 and 5",
                       "Errorbars represent 95% confidence intervals"))
s1e_heart_plot
```

I also explored whether participants reported different levels of need-threat between Time 3 and Time 5. Results are plotted in @fig-s1e-nts-across-time-plot.

```{r s1e-exploratory-NTS-mixed}
# Exploratory Mixed Model with Time --------------------------------------------
# run model
NTS_vars <- c("nts_belonging_mean", "nts_esteem_mean",
              "nts_control_mean", "nts_meaning_mean",
              "nts_mean")
s1e_rejection_NTS_df <- tibble(outcome = NTS_vars) %>%
  dplyr::mutate(formula = (paste0(outcome, " ~ desires_dummy * rejection * time + (1|id)"))) %>%
  dplyr::mutate(fit = map(formula, ~lmer(formula = as.formula(.),
                                  data = s1e_df_long)))  %>%
  dplyr::mutate(tidy = map(fit, broom::tidy)) %>%
  dplyr::mutate(described = map(fit, describe.glm))

# Create Plots
## caption
s1e_across_time_caption <- paste(sep = "\n",
                                 "Participants completed the confederate desire manipulation before Time 3 and the rejection essay before Time 5",
                                 "Errorbars represent 95% confidence intervals")
## Belonging
s1e_nts_belonging_across_time_plot <- s1e_df_long %>%
  s1e_plot_across_time(y = nts_belonging_mean, ylab = "NTS Belonging")
## Self-Esteem
s1e_nts_esteem_across_time_plot <- s1e_df_long %>%
  s1e_plot_across_time(y = nts_esteem_mean, ylab = "NTS Self-Esteem")
## Control
s1e_nts_control_across_time_plot <- s1e_df_long %>%
  s1e_plot_across_time(y = nts_control_mean, ylab = "NTS Control")
## Meaningful Existence
s1e_nts_meaning_across_time_plot <- s1e_df_long %>%
  s1e_plot_across_time(y = nts_meaning_mean, ylab = "NTS Meaningful Existence")
## Combine all plots
s1e_nts_across_time_plot <- ggarrange(s1e_nts_belonging_across_time_plot,
                                      s1e_nts_esteem_across_time_plot,
                                      s1e_nts_control_across_time_plot,
                                      s1e_nts_meaning_across_time_plot, common.legend = T) %>%
  annotate_figure(fig.lab = s1e_across_time_caption,
                  fig.lab.pos = "bottom.right",
                  fig.lab.size = 7) 
  # ggsave(here("figure", "s1e_nts_across_time_plots.png"),
        # width = 10, height = 8)



# Time 5 Moderation by Self-Esteem --------------------------------------------
s1e_T5_moderation_by_esteem <- s1e_df %>%
  lm(data = ., formula = heart_T5 ~ desires_dummy*rejection*esteem_mean)

plot_fit <- function(fit, fig.lab){
  control_plot <- fit %>%
    sjPlot::plot_model(terms = c("esteem_mean", "desires_dummy", "rejection[0]"), type = "pred") +
    #scale_x_continuous(labels = c("Low Part-Low Conf", "High Part-High Conf", "High Part-Low Conf", "Low Part-High Conf")) +
    labs(y = "Heart Manikin after Social Rejection (Time 5)", color = "Self-Esteem (Mean, +-1SD)",
         x = "Conditions", title = "Control") +
    theme(axis.text.x = element_text(angle = 45))

  rejection_plot <- fit %>%
    sjPlot::plot_model(terms = c("esteem_mean", "desires_dummy", "rejection[1]"), type = "pred") +
    #scale_x_continuous(labels = c("Low Part-Low Conf", "High Part-High Conf", "High Part-Low Conf", "Low Part-High Conf")) +
    labs(y = "Heart Manikin after Social Rejection (Time 5)", color = "Self-Esteem (Mean, +-1SD)",
         x = "Conditions", title = "Rejection") +
    theme(axis.text.x = element_text(angle = 45))

  aggregated_plot <- ggarrange(control_plot,
                               rejection_plot,
                               common.legend = TRUE) %>%
    annotate_figure(fig.lab = fig.lab)
  return(aggregated_plot)
}
plot_fit <- function(fit, fig.lab){
  control_plot <- fit %>%
    sjPlot::plot_model(terms = c( "desires_dummy", "esteem_mean", "rejection[0]"), type = "pred") +
    #scale_x_continuous(labels = c("Low Part-Low Conf", "High Part-High Conf", "High Part-Low Conf", "Low Part-High Conf")) +
    labs(y = "Heart Manikin after Social Rejection (Time 5)", color = "Self-Esteem (Mean, +-1SD)",
         x = "Conditions", title = "Control") +
    theme(axis.text.x = element_text(angle = 45))

  rejection_plot <- fit %>%
    sjPlot::plot_model(terms = c("desires_dummy", "esteem_mean",  "rejection[1]"), type = "pred") +
    scale_x_continuous(labels = c("Low Part-Low Conf", "High Part-High Conf", "High Part-Low Conf", "Low Part-High Conf")) +
    labs(y = "Heart Manikin after Social Rejection (Time 5)", color = "Self-Esteem (Mean, +-1SD)",
         x = "Conditions", title = "Rejection") +
    theme(axis.text.x = element_text(angle = 45))

  aggregated_plot <- ggarrange(control_plot,
                               rejection_plot,
                               common.legend = TRUE) %>%
    annotate_figure(fig.lab = fig.lab)
  return(aggregated_plot)
}

s1e_T5_moderation_esteem_x_rejection_plot <- s1e_T5_moderation_by_esteem %>%
  sjPlot::plot_model(terms = c("esteem_mean", "rejection"), type = "pred") +
  scale_x_continuous()

s1e_NTS_T5_vars <- c("nts_T5_belonging_mean", "nts_T5_esteem_mean", 
                     "nts_T5_control_mean", "nts_T5_meaning_mean",
                     "nts_T5_mean")

s1e_NTS_moderation_by_esteem_df <- tibble(outcome = s1e_NTS_T5_vars) %>%
  dplyr::mutate(formula = (paste0(outcome, " ~ desires_dummy * rejection * esteem_mean"))) %>%
  dplyr::mutate(fit = map(formula, ~lm(formula = as.formula(.),
                                data = s1e_df))) %>%
  dplyr::mutate(tidy = map(fit, tidy)) %>%
  dplyr::mutate(described = map(fit, describe.glm)) %>%
  dplyr::mutate(plot = map2(.x = fit, .y = outcome, ~plot_fit(.x, .y)))

s1e_NTS_moderation_by_esteem_nocond_df <- tibble(outcome = s1e_NTS_T5_vars) %>%
  dplyr::mutate(labels = c("Belonging (T5)", "Self-Esteem (T5)", "Control (T5)", "Meaningful Existence (T5)", "Overall NTS (T5)")) %>%
  dplyr::mutate(formula = (paste0(outcome, " ~ rejection * esteem_mean"))) %>%
  dplyr::mutate(fit = map(formula, ~lm(formula = as.formula(.),
                                data = s1e_df))) %>%
  dplyr::mutate(tidy = map(fit, tidy)) %>%
  dplyr::mutate(described = map(fit, describe.glm)) %>%
  dplyr::mutate(plot = map2(fit, labels, function(x = .x, title = .y){
    sjPlot::plot_model(x, terms = c("esteem_mean", "rejection"), type = "pred") +
      labs(title = title, x = "Self-Esteem", y = title)
  }))

s1e_NTS_T5_modbyesteem_plot <- ggarrange(s1e_NTS_moderation_by_esteem_nocond_df$plot[[1]],
                                         s1e_NTS_moderation_by_esteem_nocond_df$plot[[2]],
                                         s1e_NTS_moderation_by_esteem_nocond_df$plot[[3]],
                                         s1e_NTS_moderation_by_esteem_nocond_df$plot[[4]],
                                         common.legend = TRUE,
                                         labels = "AUTO") 
#  ggsave(here("figure", "s1e_nts_T5_mod_by_esteem.png"))
```

```{r s1e-nts-across-time-plot, fig.cap='Need-Threat Scores Across Time and Condition', fig.width=10, fig.height=8}
#| label: fig-s1e-nts-across-time-plot
## Combine the plots
s1e_nts_across_time_plot
```

I explored whether participants with higher (vs. lower) self-esteem reported different levels of need-threat at Time 5 (after rejection) in a regression model (predictors: the main effect of rejection, the main effect of self-esteem, and the interaction between rejection and self-esteem). @fig-s1e-nts-t5-mod-by-esteem shows the results. I did not find evidence of moderation by self-esteem for the effect of social rejection.

```{r s1e-nts-t5-mod-by-esteem}
#| label: fig-s1e-nts-t5-mod-by-esteem
#| fig-cap: Study 1e - Self-Esteem as a Possible Moderator for the Effect of Rejection on Need-Threat
s1e_NTS_T5_modbyesteem_plot 

# ggsave(here("figure", "s1e_nts_T5_mod_by_esteem.png"))
```

### Study 2

```{r s2-correlations-table}
#| label: tbl-s2-correlations-table
#| 
# Calculate means and standard deviations
s2_outcomes <- c("Heart (T1)"= "T1_Heart_1", "Heart (T2)" = "T2_Heart_1",
                 "Valence (T1)" = "T1_Valence_1", "Valence (T2)" = "T2_Valence_1",
                 "Arousal (T1)" = "T1_Arousal_1", "Arousal (T2)" = "T2_Arousal_1",
                 "Dominance (T1)" = "T1_Dominance_1", "Dominance (T2)" = "T2_Dominance_1")
s2_continuous_predictors <- c("IOS" = "IOS", "PSI" = "PSI",
                              "Narrative Eng." = "Narrative_Engagement",
                              "Immersion" = "Single_Immersion",
                              "Social World" = "OTF_Social_World", "Enjoyment" = "Enjoyment")
# Vector of variable names
s2_target_vars <- c(s2_outcomes, s2_continuous_predictors)
# Create a target columns-only df with renamed columns via `select`
s2_target_cols <- s2_df %>%
  dplyr::filter(attention_all_correct, followed_VGinstructions == "Yes") %>%
  dplyr::select(all_of(s2_target_vars))
# N, Mean, SD Table
s2_mnsdcor <- s2_target_cols %>% get_nmsd_cor_table()
# Render
s2_mnsdcor %>% as_tibble() %>%
  render_APA_kable(title = "Bivariate Correlations Among the Measures in Study 2",
                   footnote = NA,
                   col1_width = "1.5in") %>%
      footnote(general_title = "Note.",
      general = "The Ns for IOS and PSI are smaller since only people who indicated they interacted with a non-player character saw these questions. IOS = Inclusion of the Other in Self Scale. PSI = Parasocial Interactrion-Process Scale. Narrative Eng. = Narrative Engagement.",
      footnote_as_chunk = TRUE, threeparttable = TRUE) %>% 
  kable_styling_cortable()
```

#### Bivariate Scatter Plot Matrix
```{r s2-matplot, fig.cap = "Matrix Plot for Study 2 Variables", fig.height=15, fig.width=15, message=FALSE, warning=FALSE}
#| label: fig-s2-matplot
# Study 2 - Matrix Plot
s2_df %>%
  dplyr::select(essay_condition, T1_Heart_1, T1_Valence_1, T1_Arousal_1, T1_Dominance_1,
         T2_Heart_1, T2_Valence_1, T2_Arousal_1, T2_Dominance_1,
         IOS, PSI, Single_Immersion,Narrative_Engagement,
         OTF_Social_World, Enjoyment) %>%
  # Rename variables
dplyr::rename("Essay" = essay_condition, "T1 Heart" = T1_Heart_1, "T1 Valence" = T1_Valence_1,
         "T1 Arousal" = T1_Arousal_1, "T1 Dominance" = T1_Dominance_1,
         "T2 Heart" = T2_Heart_1, "T2 Valence" = T2_Valence_1,
         "T2 Arousal" = T2_Arousal_1, "T2 Dominance" = T2_Dominance_1,
         "IOS" = IOS, "PSI" = PSI, "Immersion" = Single_Immersion,
         "NE" = Narrative_Engagement,
         "Social World" = OTF_Social_World, "Enjoyment" = Enjoyment) %>%
  ggpairs(progress = FALSE,
          lower = list(continuous=wrap("smooth", 
          position=position_jitter(height=3, width=3), size = .1)))
```


```{r s2-word-cloud, fig.cap='Word Cloud for Game Titles for the Social Surrogate Condition', fig.width=10, fig.height=9}
## Word Cloud
# create words df - one row = a game title
s2_game_names <- s2_df %>%
  dplyr::filter(followed_VGinstructions == "Yes") %>%
  unnest_tokens(word, target_game_name_cl, token = "lines",
                to_lower = FALSE) %>%
  dplyr::group_by(essay_condition) %>% count(word, sort = TRUE) %>%
  dplyr::mutate(proportion = n/sum(n))

set.seed(2021)
# Word cloud for Social Surrogacy Condition
s2_game_names %>%
  dplyr::filter(essay_condition == "Social Surrogacy") %>%
  with(wordcloud(word, n, rot.per = 0, min.freq = 1,
                 scale = c(4, .8), random.color = TRUE,
                 colors = brewer.pal(5, "Set2")))
```

```{r s2-word-cloud-nonsurrogate, fig.cap='Word Cloud for Game Titles for the Non-Social Surrogate Condition', fig.width=10, fig.height=9}
# Word cloud for Non-Social Surrogacy Condition
s2_game_names %>%
  dplyr::filter(essay_condition == "Non-Social Surrogacy") %>%
  with(wordcloud(word, n, rot.per = 0, min.freq = 1,
                 scale = c(4, .8), random.color = TRUE,
                 colors = brewer.pal(5, "Set2")))
```

#### Main Analysis with Excluded Participants

```{r s2-main-analysis-with-excluded}
# Welch's t-test on T2 Belonging comparing non-social surrogacy vs. social surrogacy groups
# Main Analysis t-test
t_results_all <- s2_df %>%
  # t-test comparing the T2 belonging between the essay conditions
  t.test(formula = T2_Heart_1 ~ essay_condition,
         data = .)

# Cohen's d - 90%CI
main_cohens_d_95_all <- s2_df %>%
  effectsize::cohens_d(x = T2_Heart_1 ~ essay_condition,
                       data = ., ci = .95)
# Cohen's d - 90%CI
main_cohens_d_all <- s2_df %>%
  effectsize::cohens_d(x = T2_Heart_1 ~ essay_condition,
                       data = ., ci = .90)
# Equivalence Testing
# Equivalence test using d (`equivalence_test.effectsize_table`)
equivalence_results_all <- equivalence_test(main_cohens_d_all, range = c(-Cohen_d_target, Cohen_d_target))

# Get mean and sd
s2_all_desc <- s2_df %>% describe_by_factor(essay_condition, vars = T2_Heart_1)

# Main Results List APA Text - with all
heart2_txt_all <- list(t_results = describe.ttest(t_results_all),
                       cohen_d = main_cohens_d_all$Cohens_d %>% round(2),
                       cohen_d_low = main_cohens_d_all$CI_low %>% round(2),
                       cohen_d_high = main_cohens_d_all$CI_high %>% round(2),
                       cohen_d_APA = describe_d_ci(main_cohens_d_all),
                       cohen_d_APA95 = describe_d_ci(main_cohens_d_95_all))
heart2_txt_all <- append(heart2_txt_all,
                         list(non_surrogate_msd = to_msd(heart2_txt_all$non_surrogate_mean,
                                                         heart2_txt_all$non_surrogate_sd),
                              surrogate_msd = to_msd(heart2_txt_all$surrogate_mean,
                                                     heart2_txt_all$surrogate_sd)))
# Plot
plot_T2_Heart <- s2_df %>%
  ggplot(aes(x = essay_condition, color = essay_condition,
             y = T2_Heart_1)) +
  # Violin, errorbar, datapoints
  default_violin +
  # Remove legend
  guides(color = FALSE) +
  # Labels
  labs(y = "Heart Manikin (Time 2)",
       x = "Essay Condition",
       caption = paste("Errorbars represent 95% confidence intervals",
                       paste(heart2_txt_all$t_results, heart2_txt_all$cohen_d_APA95, sep = ", "),
                       sep = "<br>")) +
  scale_x_discrete(labels = str_to_title) 
  # save
  # ggsave(here("plot","s2_heart2_plot.png"), width = 6, height = 4)
```

In the main analysis, I excluded participants based on the preregistered exclusion procedure. Here, I report results including all participants. I used the entire dataset including excluded participats to perform Welch's *t*-test to compare the post-esaay Heart Manikin scores (Time 2) between the participants who wrote about the social surrogacy video game and those who wrote about the non-social surrogacy video game. Results were consistent with the analysis without the exculuded participants: participants who wrote about the social surrogacy game (`r heart2_txt_all$surrogate_msd`) reported similar levels of belonging compared with those who wrote about a non-surrogacy game (`r heart2_txt_all$non_surrogate_msd`, `r heart2_txt_all$t_results`).

#### Natural Language Processsing for Essays

I used natural language processing to explore words used in the video game essays. @fig-s2-nlp-plot shows the proportion of the words used within each essay conditions.
Words such as "character" and "story" appeared more frequently in the social surrogate essays compared to non-social surrogate essays. On the other hand, words such as "cards", "goal" appeared more frequently in the non-social surrogate essays than in social surrogate essays.
```{r s2-nlp}

# Load Public text file - Anonymous
s2_VG_txt <- read_rds(here("data_public", "Study2_VG_txt.rds"))
# Convert to wide, one row is now condition x word
s2_VG_txt_wide <- s2_VG_txt %>% dplyr::select(-n) %>%
  pivot_wider(names_from = essay_condition,
              values_from = proportion)
# Create a frequency plot
s2_VG_word_freq_plot <- s2_VG_txt %>%
  dplyr::filter(n > 50) %>%
  dplyr::mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word)) +
  geom_col() +
  labs(y = NULL) +
  facet_wrap(essay_condition ~ ., nrow = 2)
```

```{r s2-nlp-plot}
#| label: fig-s2-nlp-plot
#| fig-cap: Proportions of Words Used in Participants Essays Within Each Video Game Conditions. Words along the dashed line appeared equally in across social surrogacy and non-social surrogacy conditions. Words in the upper diagonal appeared more frequently in the social surrogacy condition than in the non-social surrogacy condition. Words in the lower diagnoal appeared more frequently in the non-social surrogacy condition.
#| 
# expect a warning about rows with missing values being removed
s2_VG_txt_wide %>%
  dplyr::filter(!str_detect(word, "\\d+")) %>%
  ggplot(aes(x = `Non-Social Surrogacy`, y = `Social Surrogacy`)) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001),
                       low = "darkslategray4", high = "gray75") +
  theme(legend.position="none") +
  labs(y = "Social Surrogacy", x = "Non-Social Surrogacy")
```

#### Exit Questions

Participants saw two debrief questions, one referring to the purpose of the study, and another asking them to share anything about the study. I presented the debriefing questions in a randomized order to explore whether participants provided different amount of information if they were asked about the purpose of the study first, or they were asked to share anything. Results are presented in @fig-s2-exit-questions-plot. In writing about the purpose of the study, participants who were asked about the purpose of the study first left a longer answer than those who were asked to share anything first.

```{r s2-exit-questions}
# Summary df with means
s2_exit_q_summary <- s2_df %>%
  describe_by_factor(Exit_Q_Order, vars = c(Share_Anything_Len, Study_Purpose_Len)) %>%
  # User func
  get_APA_from_msd
# T tests may not be optimal given that the distribution is positively skewed
#t.test(Share_Anything_Len ~ Exit_Q_Order, data = s2_df)
#t.test(Study_Purpose_Len ~ Exit_Q_Order, data = s2_df)
```

```{r s2-exit-questions-plot, fig.cap='Study 2 - Lengths of Participant Answers to Exit Questions Across Question Order'}
#| label: fig-s2-exit-questions-plot
# Share anything
s2_share_anything_plot <- s2_df %>% dplyr::filter(!is.na(Exit_Q_Order)) %>%
  ggplot(aes(y = Share_Anything_Len, x = Exit_Q_Order, color = Exit_Q_Order)) +
  default_violin +
  ylab("Answer to 'Share Anything' Question\n(Number of Characters)") +
  xlab("Question Order") +
  labs(color = "Question Order")
# Study Purpose
s2_study_purpose_plot <- s2_df %>% dplyr::filter(!is.na(Exit_Q_Order)) %>%
  ggplot(aes(y = Study_Purpose_Len, x = Exit_Q_Order, color = Exit_Q_Order)) +
  default_violin +
  ylab("Answer to 'Study Purpose' Question\n(Number of Characters)") +
  xlab("Question Order") +
  labs(color = "Question Order")
# Arrange the plots
ggarrange(s2_share_anything_plot, s2_study_purpose_plot,
          common.legend = TRUE)
```

### Study 3

```{r appendix-s3-correlations-table}
#| label: tbl-appendix-s3-correlations-table
# Calculate means and standard deviations
s3_outcomes <- c("Heart (T1)"= "T1_Heart_1", "Heart (T2)" = "T2_Heart_1",
                 "Valence (T1)" = "T1_Valence_1", "Valence (T2)" = "T2_Valence_1",
                 "Arousal (T1)" = "T1_Arousal_1", "Arousal (T2)" = "T2_Arousal_1",
                 "Dominance (T1)" = "T1_Dominance_1", "Dominance (T2)" = "T2_Dominance_1")
s3_continuous_predictors <- c("IOS" = "IOS", "Immersion" = "Single_Immersion",
                              "Social World" = "OTF_Social_World",
                              "Identification" = "PC_Identification",
                              "Enjoyment" = "Enjoyment")
s3_target_vars <- c(s3_outcomes, s3_continuous_predictors)
# Target columns
s3_target_cols <- s3_df %>% dplyr::filter(attention_all_correct) %>% dplyr::select(all_of(s3_target_vars))
# N, Mean, SD Table
s3_nmsd_table <- s3_target_cols %>% summarise_descriptives()
# Correlation Table with stars
s3_cortable <- s3_target_cols %>% corstarsl
# Combine the two tables
s3_mnsdcor <- s3_nmsd_table %>% cbind(s3_cortable)
# Render
s3_mnsdcor %>% as_tibble() %>%
  render_APA_kable(title = "Bivariate Correlations among the Measures in Study 3") %>%
        footnote(general_title = "Note.",
      general = "*p .05. IOS = Inclusion of the Other in Self Scale. The N of IOS is smaller since only those interacted with an NPC answered this question. The Ns for dominance, social world, identification, and enjoyment are smaller due to programming errors and participants skipping questions.",
      footnote_as_chunk = TRUE,
      threeparttable = TRUE) %>% 
  kable_styling_cortable()
```

```{r appendix-s3-ggpairs, fig.cap='Study 3 - Bivariate Scatter Plot Matrix',fig.height=15, fig.width=15, out.width='100%', message=FALSE, warning=FALSE}
# GG Pairs for Study 3
s3_df %>%
  dplyr::select(parasocial, social_world, T1_Heart_1, T1_Valence_1, T1_Arousal_1, T1_Dominance_1,
         T2_Heart_1, T2_Valence_1, T2_Arousal_1, T2_Dominance_1,
         IOS, Single_Immersion,
         OTF_Social_World,
         PC_Identification) %>%
  # Rename variables
dplyr::rename("Parasocial" = parasocial, "Social World" = social_world,
         "Heart T1" = T1_Heart_1, "Valence T1" = T1_Valence_1,
         "Arousal T1" = T1_Arousal_1, "Dominance T1" = T1_Dominance_1,
         "Heart T2" = T2_Heart_1, "Valence T2" = T2_Valence_1,
         "Arousal T2" = T2_Arousal_1, "Dominance T2" = T2_Dominance_1,
         "IOS" = IOS, "Immersion" = Single_Immersion,
         "OTF SW" = OTF_Social_World,
         "PCID" = PC_Identification) %>%
  ggpairs(progress = FALSE,
          lower = list(continuous=wrap("smooth", position=position_jitter(height=3, width=3),
                                       size = .1)))
```

## Software Programs Used 

```{r}
# List softwares used
knitcitations::cite_options(citation_format = "pandoc")
sotwares_used <- knitcitations::read.bibtex("packages.bib")
```
In writing my dissertation, I used R packages and software programs developed by the following authors: `r knitcitations::citet(sotwares_used)`



## Instituional Review Board Approval Letters

```{r, out.width='100%'}
knitr::include_graphics("pdf/IRB_letter1.pdf")
```

```{r, out.width='100%'}
knitr::include_graphics("pdf/IRB_letter2.pdf")
```


## Permissions

The current dissertation includes the following published work: Sunami, N., Nadzan, M. A., &
Jaremka, L. M. (2019). The bi‐dimensional rejection taxonomy: Organizing
responses to interpersonal rejection along antisocial--prosocial and
engaged--disengaged dimensions. Social and Personality Psychology
Compass. <https://doi.org/10.1111/spc3.12497>.  I have the right to self-archive this article to the institutional repository (under C.2.a in the attached copyright transfer agreement):

> The right to self-archive the Accepted Version on: the Contributor’s personal website; the Contributor’s company/institutional repository or archive; Compliant SCNs; and not for profit subject-based repositories such as PubMed Central, all subject to an embargo period of 12 months for scientific, technical and medical (STM) journals and 24 months for social science and humanities (SSH) journals following publication of the Final Published Version.

```{r, out.width='100%'}
knitr::include_graphics("pdf/copyright.pdf")

# How to insert multiple page pdfs:
# https://stackoverflow.com/questions/52486342/how-to-add-a-multipage-pdf-to-rmarkdown
```
