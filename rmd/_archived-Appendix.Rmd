---
title: "Appendix"
output: 
  bookdown::html_document2: 
    code_folding: hide
---


```{r setup}
# Load packages
library(tidyverse)
library(codebook) # to generate codebook
library(here)
library(car) # for the type III SS in ANOVA
library(emmeans)
library(effectsize) # for equivalence tests and effect size estimation
library(GGally) # for ggpairs
library(apastats)

# Dodge positions for plots
dodge_pos <- position_dodge(width = .5)

# ggplot theme
ggplot2::theme_set(ggplot2::theme_minimal())

# Default width for the violin plot
default_violin_width <- 0.4

# Load Datasets
s2_df <- read_rds(here("data_public", "Study2_public.rds"))
s3_df <- read_rds(here("data_public", "Study3_public.rds"))
# For correaltion tables
# Study 1a
Study1a_target_vars <- read_rds(here("data_public", "subset", "Study1a_public_target.rds"))
```


# Correlation Tables 
## Study 1a
```{r s1a-correlation-table}
# Means, SD, and Bivariate Correlations Table 
# Reference: https://www.datadreaming.org/post/apa-tables-using-rmarkdown-part-3/
S1a_cortable <- Study1a_target_vars %>% 
  correlate() %>% 
  shave(upper = TRUE) %>% 
  fashion(decimals = 2, na_print = "-")
# Summarize n, mean, sds using the local function
S1a_t1 <- Study1a_target_vars %>% summarise_descriptives()
# Combine in tone one table 
S1a_APA <- S1a_t1 %>% cbind(S1a_cortable) %>% 
  select(-term)
# Column Labels for APA Table
S1a_colnames <- c("Variable", "$n$", "$M$","$SD$",
                  1:nrow(S1a_t1))
S1a_digits <- c(NA, 0, 2, 2,
                rep(2, nrow(S1a_t1)))
S1a_align <- c("l", "c", "c", "c",
               rep("c", nrow(S1a_t1)))
# Footnote for the table
S1a_footnote <- "Heart = the Heart Manikin, Valence = the Valence Self-Assessment Manikin, CESD = the Center for Epidemiological Studies - Depression Scale, "
# Table Title
S1a_title <- "Study 1a - Descriptive Statistics and Correlations among Variables"
# Render APA using the local function
S1a_APA %>% render_APA_kable(footnote = S1a_footnote,
                             title = S1a_title)
```

## Study 1b
```{r s1b-table}
# Study 1b - N, Mean, SD Table  - Appendix
S1b_nmsd_table <- S1b_target_variables %>% 
  select(-id, -visit) %>% 
  summarise_descriptives()
# Correlation Table
S1b_cortable <- S1b_target_variables %>% select(-id, -visit) %>% 
  correlate() %>% 
  shave(upper = TRUE) %>% 
  fashion(decimals = 2, na_print = "-")
# Combine the tables
S1b_mnsdcor <- S1b_nmsd_table %>% cbind(S1b_cortable) %>% 
  select(-term)
# Render
render_APA_kable(S1b_mnsdcor)
```

## Study 1c

## Study 1d
```{r s1d-correlogram}
# Correlogram for S1d (EVv1) - Appendix
S1d_data_target_only %>%
  ggcorr(data = ., label = TRUE, label_round = 2, label_size = 3,
         layout.exp = 3, hjust = .9,
         method = "pairwise.complete.obs") + 
  ggtitle("Study 1d Correlations")

```



## Study 1e

## Study 2


## Study 3

```{r fig.height=9, fig.width=10, message=FALSE, warning=FALSE}
# GG Pairs for Study 3
s3_df %>% 
  select(parasocial, social_world, T1_Heart_1, T1_Valence_1, T1_Arousal_1, T1_Dominance_1,
         T2_Heart_1, T2_Valence_1, T2_Arousal_1, T2_Dominance_1,
         IOS, Single_Immersion, 
         OTF_Social_World,
         PC_Identification) %>% 
  # Rename variables
  rename("Parasocial" = parasocial, "Social World" = social_world,
         "Heart T1" = T1_Heart_1, "Valence T1" = T1_Valence_1,
         "Arousal T1" = T1_Arousal_1, "Dominance T1" = T1_Dominance_1,
         "Heart T2" = T2_Heart_1, "Valence T2" = T2_Valence_1, 
         "Arousal T2" = T2_Arousal_1, "Dominance T2" = T2_Dominance_1,
         "IOS" = IOS, "Immersion" = Single_Immersion, 
         "Social World MC" = OTF_Social_World,
         "PC ID" = PC_Identification) %>%
  ggpairs(progress = FALSE)

# facet_grid(parasocial ~ social_world)
```

# Bivariate Forest Plots 
## Study 1b
```{r s1b-forest, fig.width=10, fig.height=12, chache=TRUE}
# Forest plot for all the correlations acros Times 1-3 (Appendix)
ggplot(S1b_cor_CIs,
       aes(y=label, x=estimate,
           color = type)) +
  #Add data points and color them black
  geom_point()+
  #add the CI error bars - 90%
  geom_errorbarh(aes(xmin = conf.low_model90, xmax = conf.high_model90), height = .5, size = .5) +
  #add the CI error bars - 95%
  geom_errorbarh(aes(xmin = conf.low_model95, xmax = conf.high_model95), height = .5, size = .5) +
  #Specify the limits of the x-axis and relabel it to something more meaningful
  scale_x_continuous(limits=c(-1,1), name='Correlation Coefficient with Heart Manikin')+
  #Give y-axis a meaningful label
  ylab('Variable') +
  # Legend
  scale_color_discrete(name = "Hypothesized\nValidity") + 
  #Add a vertical dashed line indicating an effect size of zero, for reference
  geom_vline(xintercept=0, color='black', linetype='dashed') +
  #Create sub-plots (i.e., facets) based on levels of setting
  #And allow them to have their own unique axes (so authors don't redundantly repeat)
  ## Facet nested 
  # facet_grid(type+time~outcome, scales= 'free', space='free') + 
  ggh4x::facet_nested(type + time ~ outcome, scales= 'free', space='free') +
  ggtitle("Study 1b (RAIv1): Correlation Coefficients with the Heart Manikin\nacross Visits 1-3") + 
  # Add SESOI lines
  SESOIgeom
```

## Study 1c
```{r s1c-all-cors-plot, fig.width=9, fig.height=5}
# Forestplot - all correlations, except the ones for the mixed model 
S1c_cor_CIs %>% 
  ggplot(aes(y = label, x = estimate,
           color = type)) +
  # Dta points 
  geom_point()+
  # CI error bars - 90%
  geom_errorbarh(aes(xmin = conf.low_model90, xmax = conf.high_model90), height = .3, size = .3) +
  # CI error bars - 95%
  geom_errorbarh(aes(xmin = conf.low_model95, xmax = conf.high_model95), height = .3, size = .3) +
  # Specify the limits of the x-axis and relabel it to something more meaningful
  scale_x_continuous(limits=c(-1,1), name='Correlation Coefficient with Heart Manikin')+
  #Give y-axis a meaningful label
  ylab('Variable') +
  # Legend labels 
  scale_color_discrete(name = "Hypothesized\nValidity") + 
  #Add a vertical dashed line indicating an effect size of zero, for reference
  geom_vline(xintercept=0, color='black', linetype='dashed') +
  # Facet nested 
  ggh4x::facet_nested(type + time ~ outcome, scales= 'free', space='free') +
  ggtitle("Study 1c (ARv1): Correlation Coefficients with the Heart Manikin") +
  # Add SESOI
  SESOIgeom
```

## Study 1d (EVv1)
```{r s1d-all-forestplot, fig.width=10, fig.height=12}
## Forestplot
S1d_cor_CIs %>% 
  ggplot(aes(y = forcats::fct_inorder(label), x = estimate, color = type)) +
  # SESOI and ZERO
  geom_zeroSESOI + 
  # Dta points 
  geom_point()+
  # CI error bars - 90%
  geom_errorbarh(aes(xmin = conf.low_model90, xmax = conf.high_model90), height = .3, size = .3) +
  # CI error bars - 95%
  geom_errorbarh(aes(xmin = conf.low_model95, xmax = conf.high_model95), height = .3, size = .3) +
  # x-axis label and limits
  scale_x_continuous(limits=c(-1,1), name='Correlation Coefficient with Heart Manikin')+
  # y-axis label
  ylab("Measure") +
  # Legend Title
  scale_color_discrete(name = "Hypothesized \nValidity") + 
  # Facet the graph by type, time, and outcome
  ggh4x::facet_nested(type + time ~ outcome, scales= 'free', space='free') +
  # Title
  ggtitle("Study 1d (EVv1) - Correlation Coefficients with \nthe Heart Manikin") + 
  # Caption
  labs(caption = paste(sep = "\n",
                       "Errorbars represent 90% (inner tick) and 95% (outer tick) confidence intervals",
                       sprintf("The vertical dashed line represents the smallest effect size of interest (SESOI, |r| = %s)", SESOI_r),
       "Participant Desire Manipulation happened between Times 1 and 2.",
       "Rejection Manipulation happened between Times 2 and 3."))
```

## Study 1e
```{r s1e-cor-forestplot, fig.width = 14, fig.height = 10}
# Study 1e - Correlations Forest Plot
S1e_cor_CIs %>% 
  ggplot(aes(y = label, x = estimate, color = type)) +
  # SESOI and Zero
  geom_zeroSESOI +
  # Data points 
  geom_point()+
  # CI error bars - 90%
  geom_errorbarh(aes(xmin = conf.low_model90, xmax = conf.high_model90), height = .3, size = .3) +
  # CI error bars - 95%
  geom_errorbarh(aes(xmin = conf.low_model95, xmax = conf.high_model95), height = .3, size = .3) +
  # x-axis limits and label
  scale_x_continuous(limits=c(-1,1), name='Correlation Coefficient')+
  # y-axis label
  ylab('Variable') +
  # Legend Title
  scale_color_discrete(name = "Hypothesized \nValidity") + 
  # Facet nested
  ggh4x::facet_nested(type + time ~ outcome, scales= 'free', space='free') +
  # Title
  ggtitle("Study 1e (NPSv2): Correlation Coefficients with Heart Manikin Scores") + 
  # Caption
  labs(caption = "") + 
  # Add SESOI 
  SESOIgeom
```

# Participants per Condition
```{r}
# Study 2 - Participants by Condition
s2_participant_plot <- s2_df %>% 
  filter(attention_all_correct == TRUE) %>%
  ggplot(aes(x = essay_condition, fill = essay_condition)) +
  geom_bar() + 
  # labels
  ggtitle("Study 2: Number of Participants by Condition") +
  xlab("Parasocial Relationship Condition") +
  ylab("Count") + 
  # Y Breaks by 1 
  scale_y_continuous(breaks = seq(0, 344, 10)) + 
  # Remove Legend 
  guides(fill = FALSE)
####
```




```{r}
# Visualize how many participants per condition passed attention checks
s2_df %>% ggplot(aes(x = attention_rejection_correct,
                     fill = attention_VG_correct)) + geom_bar() +
  # Labels
  xlab("Attention Check for Rejection (Correct)") +
  ylab("Count") +
  scale_fill_discrete(name = "Attention Check \nfor Video Game \n(Correct)")  + 
  # Y Breaks by 1 
  scale_y_continuous(breaks = seq(0, 344, 10)) 


# Create a df with those who passed the attention check
s2_included <- s2_df %>% filter(attention_all_correct == TRUE)
```


# Matrix Plots
```{r s2-matplot, fig.cap = "Matrix Plot for Study 2 Variables", fig.height=15, fig.width=15, message=FALSE, warning=FALSE}
# Study 2 - Matrix Plot 
s2_df %>% 
  select(essay_condition, T1_Heart_1, T1_Valence_1, T1_Arousal_1, T1_Dominance_1,
         T2_Heart_1, T2_Valence_1, T2_Arousal_1, T2_Dominance_1,
         IOS, PSI, Single_Immersion,Narrative_Engagement, 
         OTF_Social_World, Enjoyment) %>% 
  # Rename variables
  rename("Essay" = essay_condition, "T1 Heart" = T1_Heart_1, "T1 Valence" = T1_Valence_1,
         "T1 Arousal" = T1_Arousal_1, "T1 Dominance" = T1_Dominance_1,
         "T2 Heart" = T2_Heart_1, "T2 Valence" = T2_Valence_1, 
         "T2 Arousal" = T2_Arousal_1, "T2 Dominance" = T2_Dominance_1,
         "IOS" = IOS, "PSI" = PSI, "Immersion" = Single_Immersion, 
         "NE" = Narrative_Engagement,
         "Social World" = OTF_Social_World, "Enjoyment" = Enjoyment) %>%
  ggpairs(progress = FALSE,
          lower = list(continuous=wrap("points", position=position_jitter(height=3, width=3),
                                       size = .1)))
```

# Descriptives
```{r}
descriptives_table <- s2_df %>% 
  select(essay_condition, T1_Heart_1, T1_Valence_1, T1_Arousal_1, T1_Dominance_1,
         T2_Heart_1, T2_Valence_1, T2_Arousal_1, T2_Dominance_1,
         IOS, PSI, Single_Immersion,Narrative_Engagement, 
         OTF_Social_World, Enjoyment) %>% 
  group_by(essay_condition) %>%
  summarize(across(everything(), 
                   list(mean = ~mean(., na.rm = TRUE), sd = ~sd(., na.rm = TRUE)))) %>%
  mutate(across(-essay_condition,
                ~round(., 2)))
```



# Proposed Analyses
```{r}
# Welch's t-test on T2 Belonging comparing non-social surrogacy vs. social surrogacy groups

# Visualize First
plot_T2_Heart <- s2_df %>% 
  # Only include people who got the attention check right
  filter(attention_all_correct == TRUE) %>% 
  ggplot(aes(x = essay_condition, color = essay_condition,
             y = T2_Heart_1)) +
  # Violin Plot 
  geom_violin(position = dodge_pos, width = default_violin_width) +
  # Plot data points
  geom_point(position = position_jitterdodge(dodge.width = .5)) +
  # Errorbar
  geom_errorbar(fun.data = mean_cl_normal, stat = "summary", width = .1,
                position = dodge_pos) +
  # Plot means 
  geom_point(stat = "summary", fun.data = mean_cl_normal, shape = 21, fill = "white") +
  # Remove legend 
  guides(color = FALSE) + 
  # Labels
  labs(y = "Heart Manikin (Time 2)",
       x = "Essay Condition") +
  scale_color_discrete(name = "Essay") +
  scale_x_discrete(labels = str_to_title)

# Main Analysis t-test
t_results <- s2_df %>% 
  # Include only those who passed the attention check 
  filter(attention_all_correct == TRUE) %>% 
  # t-test comparing the T2 belonging between the essay conditions
  t.test(formula = T2_Heart_1 ~ essay_condition,
         data = .)

# Cohen's d 
main_cohens_d <- s2_df %>%
  # Include only those who passed the attention check 
  filter(attention_all_correct == TRUE) %>% 
  cohens_d(x = T2_Heart_1 ~ essay_condition,
           data = ., ci = .90)

# Equivalence Testing
# SESOI for ROPE
Cohen_d_target <- 0.35

# Equivalence test using d (`equivalence_test.effectsize_table`)
equivalence_results <- equivalence_test(main_cohens_d, range = c(-Cohen_d_target, Cohen_d_target))

# Main Results List APA Text
main_txt <- list(t_results = describe.ttest(t_results),
                 non_surrogate_mean = NA,
                 non_surrogate_sd = NA,
                 surrogate_mean = NA,
                 surrogate_sd = NA,
                 cohen_d = main_cohens_d$Cohens_d %>% round(2),
                 cohen_d_low = main_cohens_d$CI_low %>% round(2),
                 cohen_d_high = main_cohens_d$CI_high %>% round(2),
                 cohen_d_APA = sprintf("_d_ = %s, %s%%CI [%s, %s]",
                                       main_cohens_d$Cohens_d %>% round(2),
                                       main_cohens_d$CI * 100, # convert to %
                                       main_cohens_d$CI_low %>% round(2),
                                       main_cohens_d$CI_high %>% round(2)))

```

**Main Analysis.** I performed Welch's t-test to compare the belonging of rejected participants who wrote about the social surrogacy video game with rejected participants who wrote about the social surrogacy video game at Time 2. Based on the social surrogacy hypothesis, I expected that participants who wrote about the social surrogacy video game would have higher belonging than those who wrote about the non-social surrogacy video game. Contrary to the hypothesis, participants who wrote about the social surrogacy game (MEAN) showed similar levels of belonging compared with those who wrote about a non-surrogacy game (MEAN, `r main_txt$t_results`).




Since the obtained p-value was greater than .05, I performed the two one-sided tests of equivalence to examine if the obtained effect size is theoretically equivalent to zero as planned (Lakens, 2017). I considered the effect size of _d_ = 0.35 as the smallest effect size of interest (SESOI). Thus, any effect sizes between _d_ = -0.35 and _d_ = 0.35 are theoretically equivalent to zero. To compare the observed effect size with the SESOI, I calculated the 90% confidence interval around the observed effect size. Then, I compared this confidence interval with _d_ = -0.35 and _d_ = 0.35. I  set the confidence to 90% because the TOST procedure involves two one-sided tests each with a 5% alpha (Lakens, 2017).
Results showed that the observed effect size estimate fell within -0.35 < _d_ < 0.35, and its observed confidence interval did not include d = -0.35 or d = 0.35 (`r main_txt$cohen_d_APA`). Thus, I consider that the observed effect size is theoretically equivalenet to zero.



```{r}
# Probing Effectiveness of Rejection Induction.
# T1 vs T2 change score
s2_df_long <- s2_df %>% 
  select(PROLIFIC_PID, essay_condition, T1_Heart_1, T2_Heart_1) %>%
  # Transform to long (select variables that needed to be a name-value pair)
  pivot_longer(c(T1_Heart_1, T2_Heart_1)) %>% 
  # Factor for T1 and T2
  mutate(Time = case_when(name == "T1_Heart_1" ~ "Time 1",
                          name == "T2_Heart_1" ~ "Time 2"),
         Time = factor(Time))

# T-test
effectivenss <- s2_df %>%
  filter(attention_all_correct == TRUE,
         essay_condition == "non-social surrogacy") %>%
  t.test(formula = Pair(T1_Heart_1, T2_Heart_1) ~ 1, data = .)

# Cohen's d
effectivenss_d <- cohens_d(s2_df$T1_Heart_1, s2_df$T2_Heart_1, paird = TRUE)

# Equivalence test
effectivenss_equivalence <- equivalence_test(effectivenss_d)

# Plot among the non-social surrogate 
s2_df_long %>%
  filter(essay_condition == "non-social surrogacy") %>%
  # Start the ggplot 2 (data from the above)
  ggplot(aes(x = Time, y = value, fill = Time)) + 
  # Add violin plot
  geom_violin(width = default_violin_width) + 
  # Add confidence intervals
  stat_summary(fun.data = mean_cl_normal, 
               fun.args = list(conf.int = .95),
               geom = "errorbar", width = .2) + 
  # Add the mean 
  geom_point(stat = "summary", fun.data = mean_cl_normal, shape = 21) +
  # Add actual data points 
  geom_point(position = "jitter", size = .8) +
  # Labels
  scale_y_continuous(name = "Heart Manikin") +
  labs(caption = "Errorbars represent 95% confidence intervals") + 
  theme_minimal() + 
  # Remove Legends
  guides(fill = FALSE, color = FALSE)

```

*Probing Effectiveness of Rejection Induction.* I will probe the effectiveness of the rejection induction by comparing the Heart Manikin scores at Times 1 and 2 among the participants in the non-social surrogate game condition. If the rejection induction is effective, I expect that these participants will report lower belonging after the rejection induction (Time 2) compared with the baseline (Time 1). To test this possibility, I will run a paired-samples t-test comparing the Heart Manikin scores at Times 1 vs. 2.



```{r}
# Exploratory Manipulation Checks
# Parasocial Relationships Manipulation Check ------------------------------
# Plot - Mosaic Plot 
library(ggmosaic)
plot_para_chi <- s2_df %>%
  filter(attention_all_correct == TRUE) %>% # Exclude those failed attention check 
  ggplot() +
  geom_mosaic(aes(x = product(parasocial_MC_group, essay_condition), fill = parasocial_MC_group)) + 
  # Remove the y-axis
  scale_y_discrete(labels = FALSE) +
  scale_fill_discrete(position = NULL)
# Chi-square test 
parasocial_MC_results <- s2_df %>% 
  filter(attention_all_correct == TRUE) %>% # Exclude those failed attention check 
  {chisq.test(x = .$essay_condition,
              y = .$parasocial_MC_group)}

# Parasocial Interaction Manipulation Check -----------------------------------
# Welch's t-test for Immersion Scale
PSI_MC_results <- s2_df %>% 
  filter(attention_all_correct == TRUE) %>% # Exclude those failed attention check 
  t.test(formula = PSI ~ essay_condition, data = .)
# Plot
plot_PSI <- s2_df %>% 
  # Exclude those failed attention check 
  filter(attention_all_correct == TRUE) %>% 
  ggplot(aes(x = essay_condition, y = PSI, color = essay_condition)) +
  # violin
  geom_violin(width = default_violin_width) + 
  # Errorbar
  geom_errorbar(fun.data = mean_cl_normal, stat = "summary", width = .1,
                position = dodge_pos) +
  # Plot means 
  geom_point(stat = "summary", fun.data = mean_cl_normal, shape = 21, fill = "white") +
  # Plot data points
  geom_point(position = "jitter") + 
  # Color 
  scale_color_brewer(palette="Set2") +
  # Remove legend 
  guides(color = FALSE) +
  # Labels 
  ylab("Parasocial Interaction") +
  xlab("Essay Condition") +
  # Condition value labels to title case
  scale_x_discrete(labels = str_to_title)

# Single-Item Immersion Manipulation Check -----------------------------------
# Welch's t-test for Immersion Scale
immersion_MC_results <- s2_df %>% 
  filter(attention_all_correct == TRUE) %>% # Exclude those failed attention check 
  t.test(formula = Single_Immersion ~ essay_condition, data = .)
# Plot 
plot_immersion <- s2_df %>% 
  # Exclude those failed attention check 
  filter(attention_all_correct == TRUE) %>% 
  ggplot(aes(x = essay_condition, y = Single_Immersion, color = essay_condition)) +
  # violin
  geom_violin(width = default_violin_width) + 
  # Errorbar
  geom_errorbar(fun.data = mean_cl_normal, stat = "summary", width = .1,
                position = dodge_pos) +
  # Plot means 
  geom_point(stat = "summary", fun.data = mean_cl_normal, shape = 21, fill = "white") +
  # Plot data points
  geom_point(position = "jitter") + 
  # Color 
  scale_color_brewer(palette="Set2") +
  # Remove legend 
  guides(color = FALSE) +
  # Labels 
  ylab("Immersion") +
  xlab("Essay Condition") +
  # Condition value labels to title case
  scale_x_discrete(labels = str_to_title)

# Narrative Engagement Scale Manipulation Check -----------------------------------
NE_MC_results <- s2_df %>% 
  filter(attention_all_correct == TRUE) %>% # Exclude those failed attention check 
  t.test(formula = Narrative_Engagement ~ essay_condition, data = .)
# Plot 
plot_NE <- s2_df %>% 
  # Exclude those failed attention check 
  filter(attention_all_correct == TRUE) %>% 
  ggplot(aes(x = essay_condition, y = Narrative_Engagement, color = essay_condition)) +
  # violin
  geom_violin(width = default_violin_width) + 
  # Errorbar
  geom_errorbar(fun.data = mean_cl_normal, stat = "summary", width = .1,
                position = dodge_pos) +
  # Plot means 
  geom_point(stat = "summary", fun.data = mean_cl_normal, shape = 21, fill = "white") +
  # Plot data points
  geom_point(position = "jitter") + 
  # Color 
  scale_color_brewer(palette="Set2") +
  # Remove legend 
  guides(color = FALSE) +
  # Labels 
  ylab("Narrative Engagement") +
  xlab("Essay Condition") +
  # Condition value labels to title case
  scale_x_discrete(labels = str_to_title)


# Narrative Engagement Scale Manipulation Check -----------------------------------
OTFWorld_MC_results <- s2_df %>% 
  filter(attention_all_correct == TRUE) %>% # Exclude those failed attention check 
  t.test(formula = OTF_Social_World ~ essay_condition, data = .)
# Plot 
plot_OTFWorld <- s2_df %>% 
  # Exclude those failed attention check 
  filter(attention_all_correct == TRUE) %>% 
  ggplot(aes(x = essay_condition, y = OTF_Social_World, color = essay_condition)) +
  # violin
  geom_violin(width = default_violin_width) + 
  # Errorbar
  geom_errorbar(fun.data = mean_cl_normal, stat = "summary", width = .1,
                position = dodge_pos) +
  # Plot means 
  geom_point(stat = "summary", fun.data = mean_cl_normal, shape = 21, fill = "white") +
  # Plot data points
  geom_point(position = "jitter") + 
  # Color 
  scale_color_brewer(palette="Set2") +
  # Remove legend 
  guides(color = FALSE) +
  # Labels 
  ylab("Social World") +
  xlab("Essay Condition") +
  # Condition value labels to title case
  scale_x_discrete(labels = str_to_title)

# APA compatible results

```

*Exploratory Manipulation Check.* To explore the effectiveness of the video game essay manipulation in inducing parasocial relationships, I used the combination of two sources of information: the yes/no question about the presence of parasocial interaction (i.e., whether participants interacted with the non-player characters in their essay), and the modified Inclusion of Self in the Other Scale (Aron et al., 1992). I coded each participant into three groups as follows. If a participant indicates that they did not interact with non-player characters (answering no to the yes/no question), they will be coded as “did not interact with non-player characters” (Group 1). If they indicate yes, and they score 0 on the modified Inclusion of Self in the Other Scale (Aron et al., 1992), they will be coded as “interacted with non-player characters but did not form parasocial relationships” (Group 2). All others will receive a code “interacted with non-player characters and formed parasocial relationships” (Group 3).  I will run a two-way chi-square test (Essay: Social Surrogacy vs. Non-Social Surrogacy x Groups: 1, 2, vs. 3) to examine whether those in the social surrogacy essay condition (vs. the non-social surrogacy condition) indicated they interacted with an NPCs (Group 2) and formed parasocial relationships (Group 3) rather than they did not interact with non-player characters (Group 1). This procedure allows participants to indicate that they did not interact with non-player characters, a response option not available in the modified Inclusion of Self in the Other Scale (Aron et al., 1992).

To explore the effectiveness of the video game essay in inducing social worlds, I will run a Welch’s t-test to compare the scores of the Single-Item Immersion Scale (Reysen et al., 2019), the Narrative Engagement Scale, and the on-the-fly measure of social world, between social surrogate vs. non-social surrogate video game essay conditions. I expect that rejected participants who wrote about the social surrogacy video game will report higher immersion and social worlds compared with those who wrote about their non-social surrogacy video game. 


Note that the Inclusion of Self in the Other Scale (Aron et al., 1992), the Single-Item Immersion Scale (Reysen et al., 2019), and the on-the-fly measure of social world have never been validated to measure social surrogates in video games, and thus I treat these analyses as exploratory. A failed manipulation check in this context can be ambiguous—such results can imply that (a) the manipulation was ineffective to induce parasocial relationships and social worlds, or (b) the measures were ineffective to capture the manipulated constructs. Accordingly, I will not conclude the effectiveness of the manipulation based on these exploratory analyses.



```{r}
# Exploratory Analysis of Enjoyment across Social Surrogacy vs. Non-Social Surrogacy Games. 
# t-test
enjoyment_results <- s2_df %>% 
  # Exclude attention fails 
  filter(attention_all_correct == TRUE) %>% 
  t.test(formula = Enjoyment ~ essay_condition,
         data = .)
# Plot
enjoyment_plot <- s2_df %>% 
  # Exclude attention fails 
  filter(attention_all_correct == TRUE) %>% 
  ggplot(aes(x = essay_condition, y = Enjoyment, color = essay_condition)) + 
  # violin
  geom_violin(width = .5) + 
  # Errorbar
  geom_errorbar(fun.data = mean_cl_normal, stat = "summary", width = .1,
                position = dodge_pos) +
  # Plot means 
  geom_point(stat = "summary", fun.data = mean_cl_normal, shape = 21, fill = "white") +
  # Plot data points
  geom_point(position = "jitter") + 
  # Labels
  xlab("Essay Condition") +
  guides(color = FALSE)
# Pull APA compatible results
enjoyment_txt <- list(enjoyment_t = describe.ttest(enjoyment_results),
                      non_surrogacy_mean = descriptives_table %>%
                        filter(essay_condition == "non-social surrogacy") %>%
                        select(Enjoyment_mean) %>% pull(),
                      non_surrogacy_sd = descriptives_table %>%
                        filter(essay_condition == "non-social surrogacy") %>%
                        select(Enjoyment_sd) %>% pull(),
                      surrogacy_mean = descriptives_table %>%
                        filter(essay_condition == "social surrogacy") %>%
                        select(Enjoyment_mean) %>% pull(),
                      surrogacy_sd = descriptives_table %>%
                        filter(essay_condition == "social surrogacy") %>%
                        select(Enjoyment_sd) %>% pull()) 

non_surrogacy_msd <- sprintf("_M_ = %s, _SD_ = %s",
                             pluck(enjoyment_txt, "non_surrogacy_mean"),
                             pluck(enjoyment_txt, "non_surrogacy_sd"))
surrogacy_msd <- sprintf("_M_ = %s, _SD_ = %s",
                             pluck(enjoyment_txt, "surrogacy_mean"),
                             pluck(enjoyment_txt, "surrogacy_sd"))
enjoyment_txt <- enjoyment_txt %>% append(list("non_surrogacy_msd" = non_surrogacy_msd,
                                               "surrogacy_msd" = surrogacy_msd))

```



**Exploratory Analysis of Enjoyment across Social Surrogacy vs. Non-Social Surrogacy Games.** To explore whether levels of enjoyment differed for social Surrogacy vs. non-social Surrogacy video conditions, I performed Welch’s t-test. I did not have a priori hypothesis for this analysis. Results showed that participants in the social surrogate condition (`r enjoyment_txt$surrogacy_msd`) reported more enjoyment in playing a game in their essay than those in the non-social surrogate condition (`r enjoyment_txt$non_surrogacy_msd`, `r enjoyment_txt$enjoyment_t`, \@ref(fig:enjoyment)).



```{r enjoyment, fig.cap = "Another amazing plot"}
enjoyment_plot
```


# Non-Preregistered Exploratory Analysis

Other Manikins
```{r}
s2_df %>% 
  filter(attention_all_correct) %>%
  transmute(across(T2_Valence_1, ~map(., ~t.test))) %>% .[[1]]


# Prepare a container
s2_models <- tibble()
manikins <- s2_df %>% select(starts_with("T1"))
# T-tests across manikin variables
s2_df %>% 
  summarise(across(starts_with(c("T1", "T2")),
                   list(ttest = function(x){list(t.test(x ~ essay_condition))}))) %>%
  mutate(across(.fns = ~map(., ~.$estimate)))
```


Change score
```{r}
# Plot the changes
s2_df_long %>% 
  ggplot(aes(x = Time, y = value, group = PROLIFIC_PID, color = PROLIFIC_PID)) +
  # Line
  geom_line(alpha = 0.6) + 
  # Prediction line by group
  # geom_line(stat = "summary", fun.data = mean_cl_normal, size = 2) + 
  # Facet
  guides(color = FALSE) +
  facet_grid(. ~essay_condition)

# Spaghetti
s2_df_long %>%
  # Start the ggplot 2 (data from the above)
  ggplot(aes(x = Time, y = value, fill = Time)) + 
  # Add violin plot
  geom_violin() + 
  # Add confidence intervals
  stat_summary(fun.data = mean_cl_normal, 
               fun.args = list(conf.int = .95),
               geom = "errorbar", width = .2) + 
  # Add the mean 
  geom_point(stat = "summary", fun.data = mean_cl_normal, shape = 21) +
  # Add actual data points 
  geom_point(position = "jitter", size = .8) +
  # Add Lines conencting particiapnts
  geom_line(aes(x = Time, y = value, group = PROLIFIC_PID,
                color = NULL), alpha = .5) +
  # Labels
  scale_y_continuous(name = "Heart Manikin") +
  labs(caption = "Errorbars represent 95% confidence intervals") + 
  theme_minimal() + 
  # Remove Legends
  guides(fill = FALSE, color = FALSE) + 
  scale_x_discrete() + 
  # Facet
  facet_grid(. ~ essay_condition, labeller = labeller(essay_condition = str_to_title))

```

# Write-Up

