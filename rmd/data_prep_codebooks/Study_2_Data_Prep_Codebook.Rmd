---
title: "Study 2 Data Preparation and Codebook"
output:
  html_document:
    toc: true
    toc_depth: 4
    toc_float: true
    code_folding: 'hide'
    self_contained: true
  pdf_document:
    toc: yes
    toc_depth: 4
    latex_engine: xelatex

---


```{r setup}
library(tidyverse)
library(haven) # to read data from .sav format from Qualtrics
library(codebook) # to generate codebook
library(here)

# Codebook
knitr::opts_chunk$set(
  warning = TRUE, # show warnings during codebook generation
  message = TRUE, # show messages during codebook generation
  error = FALSE, # do not interrupt codebook generation in case of errors,
                # usually better for debugging
  echo = TRUE  # show R code
)
ggplot2::theme_set(ggplot2::theme_minimal())

```

# Load Data
Download the .sav (SPSS) file from Qualtrics and load it with `haven()`.
```{r}
# Load data
s2_sav <- "Study2.sav"
s2_df <- haven::read_sav(here("data", s2_sav))
```

# Pseudoanonmyzation Masking - Drop Unneded Variables and Drop Unfinished Responses
Dropping variables such as IP Address, and panel metadata from Qualtrics. In addition, I'm dropping the location information since they are not used in my study.
To further de-identify the participants, delete the `PROLIFIC_PID` and assign `PID`
```{r}
s2_df <- s2_df %>% 
  select(-IPAddress,
         -(RecipientLastName:RecipientEmail),
         -ExternalReference,
         -LocationLatitude,
         -LocationLongitude,
         -PROLIFIC_PID,
         -STUDY_ID,
         -SESSION_ID,
         -debug,
         -debug_condition)
# Drop Unfinished Responses (Responses without conditions are unfinished )
s2_df <- s2_df %>% 
  filter(essay_condition != "")
# Hash the ResponseID and drop it
s2_df <- s2_df %>% 
  mutate(PID = map_chr(ResponseId, openssl::sha2)) %>% 
  select(-ResponseId)
```

# New Variables
## Scale Variables
Scaled variables were
- Parasocial Interaction Process Scale (`PSI_1:PSI_12`) - Reversed items: 2, 9, 10, 
- Narrative Engagement Scale (`Narrative_Engagement_1:Narrative_Engagement_9`) - Reversed items: 1, 2, 3, 4, 5
- On-The-Fly Measure of Social World (`OTF_Social_World_1:OTF_Social_World_4`) - No reversed items
```{r}
# Parasocial Interaction Scale
PSI_rev_items <- paste0("PSI_", c(2, 9, 10)) # Reversed items
s2_df <- s2_df %>% 
  # Add "R" to the reversed items variable names
  rename_at(PSI_rev_items, add_R) %>% 
  # Apply function to reverse the items
  mutate_at(paste0(PSI_rev_items, "R"), reverse_labelled_values)
# Aggregate as a scale
s2_df$PSI <- s2_df %>% select(starts_with("PSI_")) %>%
  aggregate_and_document_scale()

# Narrative Engagement Scale
NE_rev_items <- paste0("Narrative_Engagement_", c(1, 2, 3, 4, 5)) # Reversed items
s2_df <- s2_df %>% 
  # Add "R" to the reversed items variable names
  rename_at(NE_rev_items, add_R) %>% 
  # Apply function to reverse the items
  mutate_at(paste0(NE_rev_items, "R"), reverse_labelled_values)
# Aggregate as a scale
s2_df$Narrative_Engagement <- s2_df %>% select(starts_with("Narrative_Engagement_")) %>%
  aggregate_and_document_scale()

# On-the-fly Measure of Social World ----------------------------------------
s2_df$OTF_Social_World <- s2_df %>% 
  select(starts_with("OTF_Social_World_")) %>% aggregate_and_document_scale()

# Enjoyment  ----------------------------------------
enjoyment_rev_items <- paste0("Enjoyment_", c(3)) # Reversed Item
s2_df <- s2_df %>% 
  # Add "R" to the reversed items variable names
  rename_at(enjoyment_rev_items, add_R) %>% 
  # Apply function to reverse the items
  mutate_at(paste0(enjoyment_rev_items, "R"), reverse_labelled_values)
# Aggregate as a scale
s2_df$Enjoyment <- s2_df %>% select(starts_with("Enjoyment_")) %>%
  aggregate_and_document_scale()

```
## Title Case Conditions
```{r}
s2_df <- s2_df %>% 
  mutate(essay_condition_title = str_to_title(essay_condition))
```
## Gender Identity
```{r}
s2_df <- s2_df %>% 
  mutate(across(starts_with("Gender"),
                to_factor)) %>%
  unite("Gender_Identity", Gender_1:Gender_7_TEXT,
        remove = FALSE, na.rm = TRUE, sep = " & ") %>%
  # Remove trailing "&"
  mutate(Gender_Identity = gsub('^\\s& |\\s& $', '', Gender_Identity)) %>%
  # Gropu into Female, Male, and Non-FM
  mutate(Gender_Identity_3GP = case_when(Gender_Identity == "Female" ~ "Female",
                                         Gender_Identity == "Male" ~ "Male",
                                         TRUE ~ "Other"))


```

## Racial Identity
```{r}
s2_df <- s2_df %>% 
  mutate(across(starts_with("Race_"),
                to_factor)) %>%
  unite("Race", Race_1:Race_8,
        remove = FALSE, na.rm = TRUE, sep = " & ") %>%
  # Remove trailing "&"
  mutate(Race = gsub('^\\s& |\\s& $', '', Race)) %>%
  # Grouping in to White 
  mutate(Race_8GP = case_when(Race == "American Indian, Indigenous Canadian, or Alaska Native" ~ "American Indian, Indigenous Canadian, or Alaska Native",
                              Race == "Asian" ~ "Asian",
                              Race == "Black" ~ "Black",
                              Race == "Latino/Latina, Hispanic, Chicano, or Puerto Rican" ~ "Latino/Latina, Hispanic, Chicano, or Puerto Rican",
                              Race == "Middle Eastern or North African" ~ "Middle Eastern or North African",
                              Race == "Native Hawaiian or Pacific Islander" ~ "Native Hawaiian or Pacific Islander",
                              Race == "White" ~ "White",
                              TRUE ~ "Other/Multiracial"))
```


## Parasocial Relationships Groups
```{r}
# Parasocial Relationships Manipulation Check ------------------------------
# Create variable for parasocial values 
parasocial_labels <- c("No Interaction with NPC",
                       "No Parasocial Relationship with NPC",
                       "Formed Parasocial Relationship with NPC")
# Add the labels
s2_df <- s2_df %>% 
  mutate(parasocial_MC_group = 
           case_when(Interact_with_NPC == 2 ~ 1,
                     Interact_with_NPC == 1 & IOS == 0 ~ 2,
                     Interact_with_NPC == 1 & IOS > 0 ~ 3),
         parasocial_MC_group = ordered(parasocial_MC_group,
                                       levels = c(1, 2, 3),
                                       labels = parasocial_labels))

```


## New Variable: Attention Check
```{r}
# Mark participants with Attention Checks
s2_df <- s2_df %>% 
  # Rejection Attention Check
  mutate(attention_rejection_correct = 
           case_when(Attention_Rejection == 1 ~ TRUE,
                     TRUE ~ FALSE)) %>% 
  # Social World Attention Check
  mutate(attention_VG_correct =  
           case_when(essay_condition == "social surrogacy" & Attention_VG == 1 ~ TRUE,
                     essay_condition == "non-social surrogacy" & Attention_VG == 2 ~ TRUE,
                     TRUE ~ FALSE)) %>% 
  # All Attention Checks
  mutate(attention_all_correct = 
           case_when(attention_rejection_correct == TRUE &
                       attention_VG_correct == TRUE ~ TRUE,
                     TRUE ~ FALSE))
```

## Condtiion Name to Title Case 
```{r}
# Condition names to title case
s2_df <- s2_df %>% 
  mutate(essay_condition = str_to_title(essay_condition))
```

## Text Lengths for Write-in Responses (Essay 1, Essay 2, Study Purpose, Share Anything)
```{r}
# Get Lengths for all free responses
s2_df <- s2_df %>%
    # length 
  mutate(across(c(Rejection_Essay, Surrogacy_Essay,
                  Share_Anything, Study_Purpose), 
                list(Len = str_length)))


# Debrief Questions Question Order
s2_df <- s2_df %>% 
  mutate(Exit_Q_Order = case_when(ExitQuestions_DO_Share_Anything == 1 ~ "Anything -> Purpose",
                                  ExitQuestions_DO_Share_Anything == 2 ~ "Purpose -> Anything",
                                  TRUE ~ NA_character_))
```


# Clean Video Game Titles
```{r}
# Capitalize the first letter of a string
firstup <- function(x) {
  substr(x, 1, 1) <- toupper(substr(x, 1, 1))
  x
}

# Clean the video game names
s2_df <- s2_df %>% 
  mutate(target_game_name_cl = str_remove(target_game_name, "\\s*\\([^\\)]+\\)")) %>%
  # Any Witcher 3 to 
  mutate(target_game_name_cl = case_when(str_detect(target_game_name_cl, 
                                                    regex("The Witcher 3", ignore_case = TRUE)) ~ "The Witcher 3: Wild Hunt",
                                         TRUE ~ target_game_name_cl)) %>% 
  mutate(target_game_name_cl = str_replace(target_game_name_cl, "wi sports", "Wii Sports")) %>%
  # Any tetris as tetris
  mutate(target_game_name_cl = str_replace(target_game_name_cl, "tetris", "Tetris")) %>% 
    # Any tetris as tetris
  mutate(target_game_name_cl = str_replace(target_game_name_cl, "I've enjoyed very much playing Pokémon Mystery Dungeon.", "Pokémon Mystery Dungeon")) %>% 
  # assetto corsa person
    mutate(target_game_name_cl = str_replace(target_game_name_cl, "I'm into racing games, and Forza is probably the best, since it's arcade and designed for everyone. Assetto Corsa is my fav, since its the most realistic.", "Assetto Corsa")) %>% 
  # GTA -> Grand Theft Auto
  mutate(target_game_name_cl = str_replace(target_game_name_cl, regex("gta", ignore_case = TRUE), "Grand Theft Auto")) %>% 
# Witcher 
  mutate(target_game_name_cl = str_replace(target_game_name_cl, "Witcher 3 Wild Hunt", "The Witcher 3: Wild Hunt")) %>%
# Any pokemon will be Pokemon 
  mutate(target_game_name_cl = str_replace(target_game_name_cl, "Pokemon", "Pokémon")) %>% 
  # Dragon Age
    mutate(target_game_name_cl = str_replace(target_game_name_cl, "Dragon Age Origins", "Dragon Age: Origins")) %>% 
  # Fallout 
    mutate(target_game_name_cl = str_replace(target_game_name_cl, "Fallout New Vegas", "Fallout:New Vegas"))  %>% 
  # Solitaire to Microsoft solitaire 
  mutate(target_game_name_cl = str_replace(target_game_name_cl, "^Solitaire$", "Microsoft Solitaire")) %>% 
  mutate(target_game_name_cl = str_replace(target_game_name_cl, "LCD games from The Legend of Zelda series", "The Legend of Zelda")) %>% 
  mutate(target_game_name_cl = str_replace(target_game_name_cl, "Microsoft Solitaire Collection", "Microsoft Solitaire")) %>% 
  mutate(target_game_name_cl = str_replace(target_game_name_cl, "Solitare", "Microsoft Solitaire")) %>% 
  mutate(target_game_name_cl = str_replace(target_game_name_cl, "Lonely Mountains: Downhill", "Lonely Mountains: Downhill")) %>% 
  # Remove whitespaces before and after a string
  mutate(target_game_name_cl = str_trim(target_game_name_cl)) %>% 
  # Captalize first character 
  mutate(target_game_name_cl = firstup(target_game_name_cl))


# 
```

# Video Game Coding
```{r vg-coding}
# read coder data
coderA <- read_csv(here("data", "Study2_codes", "coderA.csv")) %>%
 mutate("coder" = "A")
coderB <- read_csv(here("data", "Study2_codes", "coderB.csv")) %>%
 mutate("coder" = "B")
coderC <- read_csv(here("data", "Study2_codes", "coderC.csv")) %>%
 mutate("coder" = "C")
# Bind all data into a long format
codes_long <- coderA %>% bind_rows(coderB, coderC) %>% select(coder, everything())
# Convert to Wide
codes_wide <- codes_long %>% pivot_wider(names_from = coder ,
                                         values_from = followed_instructions)
# Agreement columns among the coders
codes_wide <- codes_wide %>% 
  mutate(agreeAB = A == B, agreeAC = A == C, agreeBC = B == C)
# Summry table showing agreement 
codes_summary <- codes_wide %>% 
  dplyr::summarize(across(c(agreeAB, agreeAC, agreeBC),
                   ~sum(.)/n()))
codes_summary <- codes_summary %>%
  pivot_longer(everything(), names_to = "pair", values_to = "agreement") %>% 
  mutate(rank = rank(desc(agreement)))
agreements_list <- codes_summary %>% select(pair, agreement) %>% deframe %>% as.list()
# (0.805 + 0.772 + 0.824)/3
# Add percentage agreements 
codes_wide <- codes_wide %>% 
  mutate(agreeAB_percent = agreements_list$agreeAB,
         agreeAC_percent = agreements_list$agreeAC,
         agreeBC_percent = agreements_list$agreeBC) %>% 
  # then roowise operation to calculate the mean of the agreement
  mutate(agree_overall_percent = mean(c(agreeAB_percent, agreeAC_percent, agreeBC_percent))) %>% 
  ungroup()
# Highest pair
highest_pair <- codes_summary %>% filter(rank == 1) %>% pull(pair)
highest_coders <- highest_pair %>% str_extract_all("[ABC]") %>% .[[1]]
third_rater <- c("A", "B", "C") %>% str_remove(paste(highest_coders, collapse = "|")) %>%
  paste(collapse = "")
one_of_highest <- str_extract(highest_pair, ".$")
# Add initial codes to the codes_wide 
codes_wide <- codes_wide %>% 
  mutate(initial_codes = !!sym(one_of_highest))
# Final codes
codes_wide <- codes_wide %>% 
  mutate(highest_pair = highest_coders %>% str_c(collapse = ""),
         third_rater = third_rater) %>% 
  mutate(followed_VGinstructions = case_when(!!sym(highest_pair) == TRUE ~ initial_codes,
                                 TRUE ~ !!sym(third_rater))) 

# Hashing 
codes_wide <- codes_wide %>% 
  mutate(PID = openssl::sha2(ResponseId) %>% as.character) %>% 
  select(-ResponseId)

# add to the main data frame
s2_df <- s2_df %>% left_join(select(codes_wide, -essay_condition, -target_game_name), by = "PID")

# Codes Table
codes_wide %>% group_by(followed_VGinstructions) %>% summarise(n = n())
```


# Convert to Long
```{r}
# Include these indices to the long datafile for exploratory analysses
s2_mc_indices <- c("Interact_with_NPC", "parasocial_MC_group", "IOS", "PSI",
                   "Narrative_Engagement", "Single_Immersion",
                   "OTF_Social_World", "Enjoyment")
# Full long-format data
s2_df_long <- s2_df %>% 
  filter(attention_all_correct == TRUE && followed_VGinstructions == "Yes") %>%
  pivot_longer(cols = c(starts_with("T1_"),
                        starts_with("T2_"))) %>% 
  mutate(Time = str_extract(name, "T1|T2"),
         Variable = str_replace(name, "T1_|T2_", "")) %>% 
  # Pivoting wider so that each variable has its own column
  pivot_wider(id_cols = c(PID, Time, essay_condition, all_of(s2_mc_indices)),
              names_from = Variable) %>%
  # Spell Out Time 1 vs Time 2 
  mutate(Time = case_when(Time == "T1" ~ "Time 1",
                          Time == "T2" ~ "Time 2")) %>%
  rename(Heart = Heart_1,
         Valence = Valence_1,
         Arousal = Arousal_1,
         Dominance = Dominance_1) %>% 
  # Re-Order Variables for the ease of inspection
  select(PID, Time, essay_condition, Heart, Valence, Arousal, Dominance,
         everything())
```

# Delete Open-Ended Responses
I exported the data to a cleaned public dataset for analysis. Since the dataset will be public, and the answers to the open-ended responses could potentially be personally identifiable, I dropped the answers to the following open-ended responses.
- Rejection essay
- Participants' responses about the purpose of the study
- Participants' responses to share anything about the study
I exported the dataset in both .rds and .csv formats. (`Study2_public.rds`, `Study2_public.csv`)
```{r}
# Drop write-in responses for the public dataset
s2_with_txt <- s2_df
s2_public <- s2_df %>%
  # Masking Essay Responses
  mutate(across(c(Rejection_Essay, NonSurrogacy_Essay, Surrogacy_Essay,
                Study_Purpose, Share_Anything), 
                ~"(Essay responses are masked to protect participant identity. Please contact naoyuki.sunami@gmail.com to obtain responses)"))
```

# Saving Reliabilities
```{r s2-save-reliabilities}
# reliabilties
s2_reliabilities <- s2_df %>% compute_reliabilities() %>%
  get_reliability_output()

s2_reliabilities %>% 
  # compress and save (otherwise 5GB < file size)
  write_rds(here("data_public", "reliability", "s2_reliability.rds"),
            compress = "gz")

```
# Stripping out Potentially Identifiable Info
```{r}
# Remove free-text responses for demographics which may contain re-identifiable info
s2_public <- s2_public %>% 
  select(-Race, -Race_6_TEXT,
         -Relationship_7_TEXT,
         -Gender_7_TEXT, -Sexori_6_TEXT)
```


# Export Public Datasets
```{r}
# Save as .rds and .csv 
write_rds(s2_public, here("data_public", "Study2_public.rds"))
write_csv(s2_public, here("data_public", "Study2_public.csv"))

# SaveLong Dataset
write_rds(s2_df_long, here("data_public", "Study2_public_long.rds"))
write_csv(s2_df_long, here("data_public", "Study2_public_long.csv"))

# Free text response public dataset ----------------------------------------
library(tidytext)
s2_with_txt <- read_rds(here("data", "Study2_with_txt.rds"))
s2_rejection_txt <- s2_with_txt %>%
  mutate(VG_Essay = case_when(essay_condition == "Social Surrogacy" ~ Surrogacy_Essay,
                              TRUE ~ NonSurrogacy_Essay)) %>%
  select(PID, essay_condition, VG_Essay) %>%
  unnest_tokens(word, VG_Essay)
# Load stop words
data(stop_words)
s2_rejection_txt_clean <- s2_rejection_txt %>% anti_join(stop_words)
# Count words and proprotions by conditions
s2_VG_txt <- s2_rejection_txt_clean %>% 
  group_by(essay_condition) %>% count(word, sort = TRUE) %>% 
  mutate(proportion = n/sum(n))
# Save the public anonymous text results 
s2_VG_txt %>% write_rds(here("data_public", "Study2_VG_txt.rds"))

# Save the cleaned private dataset for the text responses
write_rds(s2_with_txt, here("data", "Study2_with_txt.rds"))
```

# Codebook
I use `codebook` to add metadata.
```{r}
# Study Name 
metadata(s2_df)$name <- "Nami Sunami's Dissertation - Study 2"
# Study Description
metadata(s2_df)$description <- paste0("

### Download link
[Open Science Framework](https://osf.io/XXXXX)

### Preprocessing
All rating variables (i.e., actual choice, friendship, short-term relationship etc.) were corrected for prior acquaintance, which means that dates wih prior acquaintance were excluded (set to missing) on a dyadic basis.

Variables are labeled in SPSS. 

### A list of important abbreviations, prefixes and suffixes:

* PSI = Parasocial Interaction 
* PC = Player Character
")

# Study Identifier 
metadata(s2_df)$identifier <- "https://osf.io/jvk3u/"

# Date published 
metadata(s2_df)$datePublished <- "2015-10-07"

# Creator information 
metadata(s2_df)$creator <- list(
  "@type" = "Person",
  givenName = "Nami", familyName = "Sunami",
  email = "naoyuki.sunami@gmail.com", 
  affiliation = list("@type" = "Organization",
                     name = "University of Delaware, USA"))

# Citation Information
metadata(s2_df)$citation <- "XXXXXXXXX"
# URL
metadata(s2_df)$url <- "https://osf.io/XXXXXXXX/"
# Temporal Coverage
metadata(s2_df)$temporalCoverage <- "2021"
# Spacial Coverage 
metadata(s2_df)$spatialCoverage <- "Delaware, United States
# Distribution" 
metadata(s2_df)$distribution = list(
  list("@type" = "DataDownload",
       "requiresSubscription" = "http://schema.org/True",
       "encodingFormat" = "https://www.loc.gov/preservation/digital/formats/fdd/fdd000469.shtml",
       contentUrl = "https://osf.io/XXXX/download")
)

```


```{r render-codebook}
codebook(s2_df)
# Save the codebook summary information as csv
s2_codebook_tibble <- codebook_table(s2_df)
write_csv(s2_codebook_tibble,
          here("codebooks", "Study 2 - Codebook Table.csv"))
```

